from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
import logging

load_dotenv()

PERSIST_DIRECTORY = "chroma_db_metrotech"
logger = logging.getLogger(__name__)

# –ü—Ä–æ–º–ø—Ç –¥–ª—è –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤–æ–ø—Ä–æ—Å–∞ —Å —É—á–µ—Ç–æ–º –∏—Å—Ç–æ—Ä–∏–∏
contextualize_q_system_prompt = """–£—á–∏—Ç—ã–≤–∞—è –∏—Å—Ç–æ—Ä–∏—é —á–∞—Ç–∞ –∏ –ø–æ—Å–ª–µ–¥–Ω–∏–π –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–µ—Ç —Å—Å—ã–ª–∞—Ç—å—Å—è –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç –≤ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞, \
—Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π –≤–æ–ø—Ä–æ—Å, –∫–æ—Ç–æ—Ä—ã–π –º–æ–∂–Ω–æ –ø–æ–Ω—è—Ç—å –±–µ–∑ –∏—Å—Ç–æ—Ä–∏–∏ —á–∞—Ç–∞. –ù–ï –æ—Ç–≤–µ—á–∞–π –Ω–∞ –≤–æ–ø—Ä–æ—Å, \
–ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –µ–≥–æ, –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ, –≤ –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ –≤–µ—Ä–Ω–∏ –µ–≥–æ –∫–∞–∫ –µ—Å—Ç—å."""

# –û—Å–Ω–æ–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–∞ (–±–µ–∑ —Å–∞–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏)
qa_system_prompt = """
–¢—ã ‚Äî —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π –Ω–µ–π—Ä–æ-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç "–ú–µ—Ç—Ä–æ—Ç—ç—Å—Ç".
- –û—Ç–≤–µ—á–∞–π –≤–µ–∂–ª–∏–≤–æ, –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ –∏ –ø–æ –¥–µ–ª—É, –æ—Å–Ω–æ–≤—ã–≤–∞—è—Å—å –Ω–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π.
- –§–æ—Ä–º–∏—Ä—É–π –æ—Ç–≤–µ—Ç –ø–æ –æ–¥–Ω–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é. –í –∫–æ–Ω—Ü–µ –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å—Ç–∞–≤—å —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å "|".
- –ï—Å–ª–∏ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏, –∑–∞–¥–∞–π —É—Ç–æ—á–Ω—è—é—â–∏–π –≤–æ–ø—Ä–æ—Å.
- –ï—Å–ª–∏ –≤ –±–∞–∑–µ –∑–Ω–∞–Ω–∏–π –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞, —Å–æ–æ–±—â–∏ –æ–± —ç—Ç–æ–º.
- –ò—Å–ø–æ–ª—å–∑—É–π –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞ –¥–ª—è –ø–æ–¥–¥–µ—Ä–∂–∞–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞.

---
**–ö–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π:**
{context}
---
"""

class Agent:
    def __init__(self) -> None:
        logger.info("--- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ê–≥–µ–Ω—Ç–∞ '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç' ---")
        self.llm = ChatOpenAI(model_name="gpt-4o-mini", temperature=0.2, streaming=True)
        self.store = {}
        self._initialize_rag_chain()
        logger.info("--- –ê–≥–µ–Ω—Ç '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç' —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ---")

    def _initialize_rag_chain(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã RAG."""
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ RAG-—Ü–µ–ø–æ—á–∫–∏...")
        
        logger.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –≤ '{PERSIST_DIRECTORY}'...")
        embeddings = OpenAIEmbeddings(chunk_size=1000)
        self.db = Chroma(persist_directory=PERSIST_DIRECTORY, embedding_function=embeddings)
        self.retriever = self.db.as_retriever(search_type="mmr", search_kwargs={"k": 5})
        logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ.")
        
        contextualize_q_prompt = ChatPromptTemplate.from_messages(
            [("system", contextualize_q_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")]
        )
        history_aware_retriever = create_history_aware_retriever(self.llm, self.retriever, contextualize_q_prompt)

        qa_prompt = ChatPromptTemplate.from_messages(
            [("system", qa_system_prompt), MessagesPlaceholder("chat_history"), ("human", "{input}")]
        )
        question_answer_chain = create_stuff_documents_chain(self.llm, qa_prompt)
        
        rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)
        
        self.conversational_rag_chain = RunnableWithMessageHistory(
            rag_chain,
            self.get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
            output_messages_key="answer",
        )
        logger.info("--- RAG-—Ü–µ–ø–æ—á–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∞ ---")

    def reload(self):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏ RAG-—Ü–µ–ø–æ—á–∫—É."""
        logger.info("üîÉ –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ –Ω–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫—É –∞–≥–µ–Ω—Ç–∞...")
        try:
            self._initialize_rag_chain()
            logger.info("‚úÖ –ê–≥–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω —Å –Ω–æ–≤–æ–π –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π.")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ –∞–≥–µ–Ω—Ç–∞: {e}", exc_info=True)
            return False

    def get_session_history(self, session_id: str):
        if session_id not in self.store:
            self.store[session_id] = ChatMessageHistory()
        return self.store[session_id]

    def get_response_generator(self, user_question: str, session_id: str):
        stream = self.conversational_rag_chain.stream(
            {"input": user_question},
            config={"configurable": {"session_id": session_id}},
        )
        for chunk in stream:
            if 'answer' in chunk:
                yield chunk['answer']
