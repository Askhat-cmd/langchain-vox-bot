agent.py

from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_history_aware_retriever
from langchain_community.vectorstores import Chroma
from dotenv import load_dotenv
from langchain_community.chat_message_histories import ChatMessageHistory
from langchain_core.runnables.history import RunnableWithMessageHistory
import logging
import json
import os

load_dotenv()

logger = logging.getLogger(__name__)

class Agent:
    def __init__(self) -> None:
        logger.info("--- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ê–≥–µ–Ω—Ç–∞ '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç' ---")
        # –¢–µ–∫—É—â–∞—è LLM –∏ –ª–µ–Ω–∏–≤—ã–π fallback
        self.llm = self._create_llm_from_env(primary=True)
        self.fallback_llm = None
        self._fallback_chains_built = False
        self.store = {}
        self.last_kb = "general"
        try:
            self.prompts = self.load_prompts()
        except (ValueError, FileNotFoundError, json.JSONDecodeError) as e:
            logger.critical(f"–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–≥–µ–Ω—Ç–∞ –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º—ã —Å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π –ø—Ä–æ–º–ø—Ç–æ–≤. {e}", exc_info=True)
            # –ü—Ä–µ—Ä—ã–≤–∞–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ, —á—Ç–æ–±—ã –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—Ç–∏—Ç—å –∑–∞–ø—É—Å–∫ —Å –Ω–µ–≤–µ—Ä–Ω–æ–π –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–µ–π
            raise SystemExit(f"–û—Å—Ç–∞–Ω–æ–≤–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è: {e}")

        self._initialize_rag_chain()
        logger.info("--- –ê–≥–µ–Ω—Ç '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç' —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω ---")

    def _create_llm_from_env(self, primary: bool) -> ChatOpenAI:
        """–°–æ–∑–¥–∞—ë—Ç LLM –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.
        primary=True ‚Üí LLM_MODEL_PRIMARY, –∏–Ω–∞—á–µ LLM_MODEL_FALLBACK.
        """
        model_env_key = "LLM_MODEL_PRIMARY" if primary else "LLM_MODEL_FALLBACK"
        model_name = os.getenv(model_env_key, os.getenv("LLM_MODEL_PRIMARY", "gpt-4o-mini"))
        try:
            temperature = float(os.getenv("LLM_TEMPERATURE", "0.2"))
        except ValueError:
            temperature = 0.2
        logger.info(f"LLM –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è: {'PRIMARY' if primary else 'FALLBACK'} model='{model_name}', temperature={temperature}")
        return ChatOpenAI(model_name=model_name, temperature=temperature, streaming=True)

    def load_prompts(self):
        prompts_file = os.getenv("PROMPTS_FILE_PATH")
        if not prompts_file:
            raise ValueError("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PROMPTS_FILE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

        logger.info(f"–ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–æ–º–ø—Ç–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞: '{prompts_file}'")
        try:
            with open(prompts_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.error(f"–§–∞–π–ª –ø—Ä–æ–º–ø—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {prompts_file}")
            raise
        except json.JSONDecodeError as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –≤ —Ñ–∞–π–ª–µ {prompts_file}: {e}")
            raise

    def _initialize_rag_chain(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç/–ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ —Ö—Ä–∞–Ω–∏–ª–∏—â–µ –∏ RAG-—Ü–µ–ø–æ—á–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π LLM."""
        logger.info("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–ª–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ RAG-—Ü–µ–ø–æ—á–∫–∏...")

        persist_directory = os.getenv("PERSIST_DIRECTORY")
        if not persist_directory:
            raise ValueError("–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PERSIST_DIRECTORY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

        logger.info(f"–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –≤ '{persist_directory}'...")
        embeddings = OpenAIEmbeddings(chunk_size=1000)
        self.db = Chroma(persist_directory=persist_directory, embedding_function=embeddings)
        kb_k = int(os.getenv("KB_TOP_K", "3"))
        self.retriever_general = self.db.as_retriever(
            search_type="similarity", search_kwargs={"k": kb_k, "filter": {"kb": "general"}}
        )
        self.retriever_tech = self.db.as_retriever(
            search_type="similarity", search_kwargs={"k": kb_k, "filter": {"kb": "tech"}}
        )
        logger.info("–ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ.")

        # –°—Ç—Ä–æ–∏–º —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è —Ç–µ–∫—É—â–µ–π LLM
        self._build_chains_for_llm(self.llm)
        # –°–±—Ä–æ—Å–∏–º –∫—ç—à —Ñ–æ–ª–±—ç–∫–∞
        self._fallback_chains_built = False
        self.fallback_llm = None
        logger.info("--- RAG-—Ü–µ–ø–æ—á–∫–∞ —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞/–æ–±–Ω–æ–≤–ª–µ–Ω–∞ ---")

    def _build_chains_for_llm(self, llm: ChatOpenAI):
        """–°—Ç—Ä–æ–∏—Ç –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π LLM."""
        contextualize_q_prompt = ChatPromptTemplate.from_messages(
            [("system", self.prompts["contextualize_q_system_prompt"]), MessagesPlaceholder("chat_history"), ("human", "{input}")]
        )
        history_aware_retriever_general = create_history_aware_retriever(llm, self.retriever_general, contextualize_q_prompt)
        history_aware_retriever_tech = create_history_aware_retriever(llm, self.retriever_tech, contextualize_q_prompt)

        qa_prompt = ChatPromptTemplate.from_messages(
            [("system", self.prompts["qa_system_prompt"]), MessagesPlaceholder("chat_history"), ("human", "{input}")]
        )
        question_answer_chain = create_stuff_documents_chain(llm, qa_prompt)

        rag_chain_general = create_retrieval_chain(history_aware_retriever_general, question_answer_chain)
        rag_chain_tech = create_retrieval_chain(history_aware_retriever_tech, question_answer_chain)

        self.conversational_rag_chain_general = RunnableWithMessageHistory(
            rag_chain_general,
            self.get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
            output_messages_key="answer",
        )
        self.conversational_rag_chain_tech = RunnableWithMessageHistory(
            rag_chain_tech,
            self.get_session_history,
            input_messages_key="input",
            history_messages_key="chat_history",
            output_messages_key="answer",
        )

    def _route_kb(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –∏ –±—ã—Å—Ç—Ä–∞—è –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è: general | tech.
        –í—ã–±–∏—Ä–∞–µ–º 'tech', –µ—Å–ª–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω—ã —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –º–∞—Ä–∫–µ—Ä—ã; –∏–Ω–∞—á–µ 'general'."""
        if not text:
            return "general"
        t = text.lower()
        tech_markers = [
            "—Ç–µ—Ö–Ω", "—Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç", "–ø–∞—Ä–∞–º–µ—Ç—Ä", "–¥–∏–∞–ø–∞–∑–æ–Ω", "–∫–ª–∞—Å—Å —Ç–æ—á–Ω–æ—Å—Ç–∏", "–Ω–∞–≥—Ä—É–∑", "–¥–∞—Ç—á–∏–∫",
            "—Ç–µ–Ω–∑–æ", "—Ä–∞–∑—Ä—ã–≤–Ω", "–º–∞—à–∏–Ω", "—É—Å–∏–ª–∏–µ", "–∫–Ω", "–º–ø–∞", "–Ω—å—é—Ç–æ–Ω", "–º–º", "–≥–æ—Å—Ç", "iso",
            "—Å–µ—Ä—Ç–∏—Ñ", "–º–æ–¥—É–ª—å", "—á–∞—Å—Ç–æ—Ç–∞", "–≤–∏–±—Ä–æ", "—Å–æ–ø—Ä–æ—Ç–∏–≤–ª", "–ø—Ä–æ—Ç–æ–∫–æ–ª", "datasheet", "spec"
        ]
        general_markers = ["—Ü–µ–Ω–∞", "—Å—Ç–æ–∏–º–æ—Å—Ç—å", "–∫–æ–Ω—Ç–∞–∫—Ç", "–≥–∞—Ä–∞–Ω—Ç", "–¥–æ—Å—Ç–∞–≤–∫–∞", "–æ–ø–ª–∞—Ç–∞", "–∞–¥—Ä–µ—Å"]
        if any(m in t for m in tech_markers) and not any(m in t for m in general_markers):
            return "tech"
        return "general"

    def _max_relevance(self, question: str, kb: str, k: int) -> float:
        try:
            # –î–ª—è –æ—Ü–µ–Ω–∫–∏ –ø–æ—Ä–æ–≥–∞ –±–µ—Ä—ë–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –Ω–∞–ø—Ä—è–º—É—é –∏–∑ –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ —Å—Ç–æ—Ä–∞
            res = self.db.similarity_search_with_relevance_scores(
                question, k=k, filter={"kb": kb}
            )
            if not res:
                return 0.0
            return max(score for _, score in res)
        except Exception:
            return 1.0  # –µ—Å–ª–∏ —Å—Ç–æ—Ä –Ω–µ –≤–µ—Ä–Ω—É–ª –æ—Ü–µ–Ω–∫—É, –Ω–µ —Ç—Ä–∏–≥–≥–µ—Ä–∏–º —Ñ–æ–ª–±—ç–∫

    def reload(self):
        """–ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–æ–º–ø—Ç—ã, –≤–µ–∫—Ç–æ—Ä–Ω—É—é –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –∏ RAG-—Ü–µ–ø–æ—á–∫—É."""
        logger.info("üîÉ –ü–æ–ª—É—á–µ–Ω–∞ –∫–æ–º–∞–Ω–¥–∞ –Ω–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫—É –∞–≥–µ–Ω—Ç–∞...")
        try:
            self.prompts = self.load_prompts()
            # –û–±–Ω–æ–≤–∏–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –º–æ–¥–µ–ª–µ–π
            self.llm = self._create_llm_from_env(primary=True)
            self._initialize_rag_chain()
            logger.info("‚úÖ –ê–≥–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∂–µ–Ω —Å –Ω–æ–≤–æ–π –±–∞–∑–æ–π –∑–Ω–∞–Ω–∏–π –∏ –ø—Ä–æ–º–ø—Ç–∞–º–∏.")
            return True
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–µ –∞–≥–µ–Ω—Ç–∞: {e}", exc_info=True)
            return False

    def get_session_history(self, session_id: str):
        if session_id not in self.store:
            self.store[session_id] = ChatMessageHistory()
        return self.store[session_id]

    def get_response_generator(self, user_question: str, session_id: str):
        target = self._route_kb(user_question)
        # –ü–æ—Ä–æ–≥ –∏ k –±–µ—Ä—ë–º –∏–∑ env (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.2 –∏ 3)
        threshold = float(os.getenv("KB_FALLBACK_THRESHOLD", "0.2"))
        k = int(os.getenv("KB_TOP_K", "3"))
        # –û—Ü–µ–Ω–∏–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –≤—ã–±—Ä–∞–Ω–Ω–æ–π –ë–ó; –ø—Ä–∏ –Ω–∏–∑–∫–æ–π ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –≤—Ç–æ—Ä—É—é
        max_score = self._max_relevance(user_question, target, k)
        alt = "tech" if target == "general" else "general"
        if max_score < threshold:
            alt_score = self._max_relevance(user_question, alt, k)
            if alt_score > max_score:
                logger.info(
                    f"–ù–∏–∑–∫–∞—è —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å ({max_score:.2f}) –¥–ª—è {target} ‚Üí –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ {alt} ({alt_score:.2f})"
                )
                target = alt
        self.last_kb = target
        logger.info(f"–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –≤–æ–ø—Ä–æ—Å–∞ –≤ –ë–ó: {target}")
        def _stream_with_chain(use_fallback: bool):
            chain_local = (
                self.conversational_rag_chain_tech if target == "tech" else self.conversational_rag_chain_general
            )
            stream_local = chain_local.stream(
                {"input": user_question},
                config={"configurable": {"session_id": session_id}},
            )
            for chunk in stream_local:
                if 'answer' in chunk:
                    yield chunk['answer']

        def _invoke_non_streaming_with_llm(model_name: str):
            """–õ–æ–∫–∞–ª—å–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ù–ï—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–µ —Ü–µ–ø–æ—á–∫–∏ –ø–æ–¥ —É–∫–∞–∑–∞–Ω–Ω—ã–π model_name –∏ –≤–µ—Ä–Ω—É—Ç—å –ø–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç –æ–¥–Ω–æ–π —Å—Ç—Ä–æ–∫–æ–π."""
            try:
                temperature = float(os.getenv("LLM_TEMPERATURE", "0.2"))
            except ValueError:
                temperature = 0.2
            llm_local = ChatOpenAI(model_name=model_name, temperature=temperature, streaming=False)

            contextualize_q_prompt = ChatPromptTemplate.from_messages(
                [("system", self.prompts["contextualize_q_system_prompt"]), MessagesPlaceholder("chat_history"), ("human", "{input}")]
            )
            history_aware_retriever_general = create_history_aware_retriever(llm_local, self.retriever_general, contextualize_q_prompt)
            history_aware_retriever_tech = create_history_aware_retriever(llm_local, self.retriever_tech, contextualize_q_prompt)

            qa_prompt = ChatPromptTemplate.from_messages(
                [("system", self.prompts["qa_system_prompt"]), MessagesPlaceholder("chat_history"), ("human", "{input}")]
            )
            question_answer_chain = create_stuff_documents_chain(llm_local, qa_prompt)

            rag_chain_local = create_retrieval_chain(
                history_aware_retriever_tech if target == "tech" else history_aware_retriever_general,
                question_answer_chain,
            )
            runnable = RunnableWithMessageHistory(
                rag_chain_local,
                self.get_session_history,
                input_messages_key="input",
                history_messages_key="chat_history",
                output_messages_key="answer",
            )
            result = runnable.invoke(
                {"input": user_question},
                config={"configurable": {"session_id": session_id}},
            )
            text = result.get("answer", "")
            if text:
                yield text

        # –ü–æ–ø—Ä–æ–±—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –ø–∞–π–ø–ª–∞–π–Ω; –ø—Ä–∏ –æ—à–∏–±–∫–µ ‚Äî –æ–¥–∏–Ω —Ä–∞–∑ —Ñ–æ–ª–±—ç–∫ –Ω–∞ –∑–∞–ø–∞—Å–Ω—É—é –º–æ–¥–µ–ª—å
        try:
            yield from _stream_with_chain(use_fallback=False)
        except Exception as e:
            fb_model = os.getenv("LLM_MODEL_FALLBACK")
            primary_model = os.getenv("LLM_MODEL_PRIMARY", "gpt-4o-mini")
            err_text = str(e).lower()
            # –ï—Å–ª–∏ —Å—Ç—Ä–∏–º –∑–∞–ø—Ä–µ—â—ë–Ω –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–µ–π/–º–æ–¥–µ–ª—å—é ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –ù–ï—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —Ä–µ–∂–∏–º –Ω–∞ –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏
            if "unsupported_value" in err_text or "verify organization" in err_text or "param': 'stream" in err_text:
                logger.warning("–°—Ç—Ä–∏–º–∏–Ω–≥ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –¥–ª—è —Ç–µ–∫—É—â–µ–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏/–º–æ–¥–µ–ª–∏ ‚Üí –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ –ù–ï—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —Ä–µ–∂–∏–º (PRIMARY)")
                try:
                    yield from _invoke_non_streaming_with_llm(primary_model)
                    return
                except Exception as e_ns:
                    logger.error(f"–ù–µ —É–¥–∞–ª–æ—Å—å –≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–µ—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤—ã–π —Ä–µ–∂–∏–º –Ω–∞ PRIMARY: {e_ns}", exc_info=True)
            # –ï—Å–ª–∏ —Ñ–æ–ª–±—ç–∫ –æ–ø—Ä–µ–¥–µ–ª—ë–Ω ‚Äî –ø–æ–ø—Ä–æ–±—É–µ–º –µ–≥–æ (—Å—Ç—Ä–∏–º), –∑–∞—Ç–µ–º –ù–ï—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ
            if not fb_model or fb_model == primary_model:
                logger.error(f"–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–±–µ–∑ —Ñ–æ–ª–±—ç–∫–∞): {e}", exc_info=True)
                return
            logger.warning(f"–û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å —É–ø–∞–ª–∞: {e}. –ü—ã—Ç–∞–µ–º—Å—è –ø–µ—Ä–µ–∫–ª—é—á–∏—Ç—å—Å—è –Ω–∞ FALLBACK '{fb_model}'‚Ä¶")
            # –ü–æ—Å—Ç—Ä–æ–∏–º —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è fallback –æ–¥–∏–Ω —Ä–∞–∑
            try:
                if not self._fallback_chains_built:
                    self.fallback_llm = self._create_llm_from_env(primary=False)
                    self._build_chains_for_llm(self.fallback_llm)
                    self._fallback_chains_built = True
                try:
                    yield from _stream_with_chain(use_fallback=True)
                    return
                except Exception as e_fb_stream:
                    logger.warning(f"–§–æ–ª–±—ç–∫ –≤ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ–º —Ä–µ–∂–∏–º–µ –Ω–µ —É–¥–∞–ª—Å—è: {e_fb_stream}. –ü—Ä–æ–±—É–µ–º –ù–ï—Å—Ç—Ä–∏–º–∏–Ω–≥–æ–≤–æ‚Ä¶")
                    yield from _invoke_non_streaming_with_llm(fb_model)
            except Exception as e2:
                logger.error(f"–§–æ–ª–±—ç–∫ –º–æ–¥–µ–ª—å —Ç–∞–∫–∂–µ –Ω–µ —Å–ø—Ä–∞–≤–∏–ª–∞—Å—å: {e2}", exc_info=True)
                return


main.py

"""
–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
- WebSocket-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å Voximplant
- API –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ª–æ–≥–æ–≤
- –°—Ç–∞—Ç–∏–∫–∞ –¥–ª—è UI –ª–æ–≥–æ–≤
"""
import os, logging, uuid, json, asyncio, io, shutil, time, re
from logging.handlers import RotatingFileHandler
from datetime import datetime, timezone
from typing import Dict, Any

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Query, status, UploadFile, File, Depends, HTTPException, Security
from fastapi.security import APIKeyHeader
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from dotenv import load_dotenv

from app.backend.rag.agent import Agent
from app.backend.utils.text_normalizer import normalize as normalize_text
from app.backend.services.log_storage import insert_log, query_logs, to_csv, delete_all_logs
from scripts.create_embeddings import recreate_embeddings

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
load_dotenv()

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
os.makedirs("data/logs", exist_ok=True)
log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
log_file = "data/logs/app.log"

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–æ—Ç–∏—Ä—É–µ–º—ã–π —Ñ–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
file_handler = RotatingFileHandler(log_file, maxBytes=5*1024*1024, backupCount=5, encoding='utf-8')
file_handler.setFormatter(log_formatter)
file_handler.setLevel(logging.INFO)

# –ü–æ–ª—É—á–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä –∏ –î–û–ë–ê–í–õ–Ø–ï–ú –Ω–∞—à –æ–±—Ä–∞–±–æ—Ç—á–∏–∫, –Ω–µ —É–¥–∞–ª—è—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ.
# –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã —Å –ª–æ–≥–≥–µ—Ä–∞–º–∏ Gunicorn/Uvicorn.
root_logger = logging.getLogger()
root_logger.addHandler(file_handler)
root_logger.setLevel(logging.INFO)

logger = logging.getLogger(__name__)


app = FastAPI()
app.mount("/logs-ui", StaticFiles(directory="app/frontend/logs-ui", html=True), name="logs-ui")


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def duplicate_headers_without_hashes(text: str) -> str:
    """
    –î—É–±–ª–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ Markdown (–æ—Ç h1 –¥–æ h6) –≤ —Ç–µ–∫—Å—Ç–µ,
    –¥–æ–±–∞–≤–ª—è—è –≤–µ—Ä—Å–∏—é –±–µ–∑ —Ö—ç—à–µ–π –≤ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ.
    """
    def replacer(match):
        header_line = match.group(0)
        clean_header = header_line.lstrip('#').strip()
        return f"{header_line}\n{clean_header}"

    processed_text = re.sub(r"^(#{1,6}\s.+)", replacer, text, flags=re.MULTILINE)
    return processed_text


def _update_env_file(vars_to_set: Dict[str, str]) -> None:
    env_path = os.path.join(os.getcwd(), ".env")
    lines: list[str] = []
    if os.path.exists(env_path):
        with open(env_path, "r", encoding="utf-8") as f:
            lines = f.read().splitlines()
    keys = set(vars_to_set.keys())
    new_lines: list[str] = []
    for line in lines:
        if not line or line.strip().startswith("#"):
            new_lines.append(line)
            continue
        key = line.split("=", 1)[0].strip()
        if key in keys:
            new_lines.append(f"{key}={vars_to_set[key]}")
            keys.remove(key)
        else:
            new_lines.append(line)
    for k in keys:
        new_lines.append(f"{k}={vars_to_set[k]}")
    with open(env_path, "w", encoding="utf-8") as f:
        f.write("\n".join(new_lines) + "\n")


# --- –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö (Pydantic) ---

class PromptsUpdatePayload(BaseModel):
    """–°—Ö–µ–º–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥—è—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤."""
    greeting: str = Field(..., min_length=1, description="–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞.")
    contextualize_q_system_prompt: str = Field(..., min_length=1, description="–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏.")
    qa_system_prompt: str = Field(..., min_length=1, description="–û—Å–Ω–æ–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.")

class SearchSettingsPayload(BaseModel):
    kb_top_k: int | None = Field(None, ge=1, le=20)
    kb_fallback_threshold: float | None = Field(None, ge=0.0, le=1.0)

class ModelSettingsPayload(BaseModel):
    llm_model_primary: str | None = Field(None, description="–ò–º—è –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä 'gpt-4o-mini'")
    llm_model_fallback: str | None = Field(None, description="–ò–º—è –∑–∞–ø–∞—Å–Ω–æ–π –º–æ–¥–µ–ª–∏")
    llm_temperature: float | None = Field(None, ge=0.0, le=1.0, description="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ (0..1)")

class NormalizeRequest(BaseModel):
    text: str


# --- –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å ---
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

def get_api_key(api_key: str = Security(api_key_header)):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç API –∫–ª—é—á –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞."""
    expected_api_key = os.getenv("API_SECRET_KEY")
    if not expected_api_key:
        logger.warning("API_SECRET_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞. –≠—Ç–æ –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞.")
        return # –†–∞–∑—Ä–µ—à–∞–µ–º –¥–æ—Å—Ç—É–ø, –µ—Å–ª–∏ –∫–ª—é—á –Ω–µ –∑–∞–¥–∞–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
    if not api_key or api_key != expected_api_key:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–π –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π API –∫–ª—é—á",
        )
    return api_key


try:
    agent = Agent()
    logger.info("–ê–≥–µ–Ω—Ç '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç' —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
except SystemExit as e:
    logger.critical(f"–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è –∏–∑-–∑–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏: {e}")
    agent = None
except Exception as e:
    logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞ '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç': {e}", exc_info=True)
    agent = None

# --- –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–≤–æ–Ω–∫–∞–º–∏ ---
active_calls: Dict[str, Dict[str, Any]] = {}

# --- –†–æ—É—Ç—ã ---

@app.get("/")
async def root():
    return HTMLResponse(
        "<h3>–ë—ç–∫–µ–Ω–¥ '–ú–µ—Ç—Ä–æ—Ç—ç—Å—Ç' –∞–∫—Ç–∏–≤–µ–Ω.<br>"
        "‚Ä¢ WebSocket¬†‚Äî¬†<code>/ws</code><br>"
        "‚Ä¢ UI –ª–æ–≥–æ–≤¬†‚Äî¬†<code>/logs-ui/</code><br>"
        "‚Ä¢ –¢–µ—Å—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏¬†‚Äî¬†<code>POST /api/normalize</code></h3>"
    )

# ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–æ—É—Ç—ã –¥–ª—è –ª–æ–≥–æ–≤ –∏ CSV –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
@app.get("/logs")
async def get_logs(q: str | None = None,
                   date_from: str | None = None,
                   date_to: str | None = None,
                   status: str | None = None):
    rows = await query_logs({"from": date_from, "to": date_to, "status": status})
    if q:
        q_low = q.lower()
        filtered_rows = []
        for r in rows:
            if q_low in (r.get("callerId") or "").lower():
                filtered_rows.append(r)
                continue
            try:
                transcript = json.loads(r["transcript_json"])
                for turn in transcript:
                    if q_low in turn.get("text", "").lower():
                        filtered_rows.append(r)
                        break
            except (json.JSONDecodeError, AttributeError):
                continue
        rows = filtered_rows
    return JSONResponse(content=rows)

@app.delete("/logs", dependencies=[Depends(get_api_key)])
async def clear_logs():
    try:
        await delete_all_logs()
        logger.info("üóëÔ∏è –í—Å–µ –ª–æ–≥–∏ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã.")
        return JSONResponse(content={"message": "–í—Å–µ –ª–æ–≥–∏ —É–¥–∞–ª–µ–Ω—ã"}, status_code=status.HTTP_200_OK)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ª–æ–≥–æ–≤: {e}", exc_info=True)
        return JSONResponse(content={"error": str(e)}, status_code=status.HTTP_500_INTERNAL_SERVER_ERROR)

@app.get("/logs/csv")
async def get_logs_csv():
    rows = await query_logs({})
    csv_data_str = await to_csv(rows)
    response_bytes = csv_data_str.encode('utf-8-sig')
    return StreamingResponse(
        io.BytesIO(response_bytes),
        media_type="text/csv",
        headers={"Content-Disposition": 'attachment; filename="call_logs.csv"'}
    )

# --- API –¥–ª—è –ë–∞–∑—ã –ó–Ω–∞–Ω–∏–π –∏ –ü—Ä–æ–º–ø—Ç–æ–≤ ---

@app.get("/api/prompts")
async def get_prompts():
    prompts_file = os.getenv("PROMPTS_FILE_PATH")
    if not prompts_file:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PROMPTS_FILE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        with open(prompts_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –ø—Ä–æ–º–ø—Ç–æ–≤: {e}")

@app.post("/api/prompts", dependencies=[Depends(get_api_key)])
async def update_prompts(payload: PromptsUpdatePayload): # NEW: –ò—Å–ø–æ–ª—å–∑—É–µ–º Pydantic –º–æ–¥–µ–ª—å
    prompts_file = os.getenv("PROMPTS_FILE_PATH")
    if not prompts_file:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PROMPTS_FILE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        # Pydantic –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–æ–¥–µ–ª—å –≤ —Å–ª–æ–≤–∞—Ä—å
        with open(prompts_file, 'w', encoding='utf-8') as f:
            json.dump(payload.dict(), f, ensure_ascii=False, indent=2)

        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∞–≥–µ–Ω—Ç–∞, —á—Ç–æ–±—ã –æ–Ω –ø–æ–¥—Ö–≤–∞—Ç–∏–ª –Ω–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        if agent and hasattr(agent, 'reload'):
            agent.reload()

        return JSONResponse(content={"message": "–ü—Ä–æ–º–ø—Ç—ã —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã."})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã: {e}")

@app.get("/api/settings")
async def get_search_settings():
    return {
        "kb_top_k": int(os.getenv("KB_TOP_K", "3")),
        "kb_fallback_threshold": float(os.getenv("KB_FALLBACK_THRESHOLD", "0.2")),
        "llm_model_primary": os.getenv("LLM_MODEL_PRIMARY", "gpt-4o-mini"),
        "llm_model_fallback": os.getenv("LLM_MODEL_FALLBACK", ""),
        "llm_temperature": float(os.getenv("LLM_TEMPERATURE", "0.2")),
    }

@app.post("/api/settings", dependencies=[Depends(get_api_key)])
async def update_search_settings(payload: SearchSettingsPayload):
    try:
        to_set: Dict[str, str] = {}
        if payload.kb_top_k is not None:
            to_set["KB_TOP_K"] = str(payload.kb_top_k)
            os.environ["KB_TOP_K"] = str(payload.kb_top_k)
        if payload.kb_fallback_threshold is not None:
            to_set["KB_FALLBACK_THRESHOLD"] = str(payload.kb_fallback_threshold)
            os.environ["KB_FALLBACK_THRESHOLD"] = str(payload.kb_fallback_threshold)

        if to_set:
            _update_env_file(to_set)
            if agent and hasattr(agent, 'reload'):
                agent.reload()
        return JSONResponse(content={"message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {e}")


@app.post("/api/model-settings", dependencies=[Depends(get_api_key)])
async def update_model_settings(payload: ModelSettingsPayload):
    try:
        to_set: Dict[str, str] = {}
        if payload.llm_model_primary is not None:
            to_set["LLM_MODEL_PRIMARY"] = payload.llm_model_primary
            os.environ["LLM_MODEL_PRIMARY"] = payload.llm_model_primary
        if payload.llm_model_fallback is not None:
            to_set["LLM_MODEL_FALLBACK"] = payload.llm_model_fallback
            os.environ["LLM_MODEL_FALLBACK"] = payload.llm_model_fallback
        if payload.llm_temperature is not None:
            to_set["LLM_TEMPERATURE"] = str(payload.llm_temperature)
            os.environ["LLM_TEMPERATURE"] = str(payload.llm_temperature)

        if to_set:
            _update_env_file(to_set)
            if agent and hasattr(agent, 'reload'):
                agent.reload()
        return JSONResponse(content={"message": "–ú–æ–¥–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {e}")


@app.post("/api/normalize")
async def api_normalize(payload: NormalizeRequest):
    try:
        normalized = normalize_text(payload.text)
        return {"raw": payload.text, "normalized": normalized}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/kb")
async def get_knowledge_base():
    kb_path = os.getenv("KNOWLEDGE_BASE_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        with open(kb_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return JSONResponse(content={"text": content})
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/kb/upload", dependencies=[Depends(get_api_key)])
async def upload_kb(file: UploadFile = File(...)):
    kb_path = os.getenv("KNOWLEDGE_BASE_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

    if not file.filename.endswith('.md'):
        raise HTTPException(status_code=400, detail="–û—à–∏–±–∫–∞: –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ .md —Ñ–∞–π–ª.")

    try:
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        content_bytes = await file.read()
        content_text = content_bytes.decode('utf-8')

        # –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç, –¥—É–±–ª–∏—Ä—É—è –∑–∞–≥–æ–ª–æ–≤–∫–∏
        logger.info("–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ...")
        enriched_content = duplicate_headers_without_hashes(content_text)
        logger.info("–ó–∞–≥–æ–ª–æ–≤–∫–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã.")


        backup_dir = "kb/backups"
        os.makedirs(backup_dir, exist_ok=True)
        timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
        backup_path = os.path.join(backup_dir, f"knowledge_base_{timestamp}.md.bak")
        if os.path.exists(kb_path):
            shutil.copy(kb_path, backup_path)
            logger.info(f"üíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {backup_path}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        with open(kb_path, "w", encoding='utf-8') as buffer:
            buffer.write(enriched_content)

        logger.info(f"‚úÖ –ù–æ–≤—ã–π —Ñ–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π '{file.filename}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.")

        asyncio.create_task(recreate_embeddings_and_reload_agent())

        return JSONResponse(status_code=202, content={"message": "–§–∞–π–ª –ø—Ä–∏–Ω—è—Ç. –ù–∞—á–∞–ª—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ –ë–ó: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")

# --- –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (TECH) ---

@app.get("/kb2")
async def get_knowledge_base_tech():
    kb_path = os.getenv("KNOWLEDGE_BASE2_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE2_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        with open(kb_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return JSONResponse(content={"text": content})
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="–§–∞–π–ª —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/kb2/upload", dependencies=[Depends(get_api_key)])
async def upload_kb_tech(file: UploadFile = File(...)):
    kb_path = os.getenv("KNOWLEDGE_BASE2_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE2_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

    if not file.filename.endswith('.md'):
        raise HTTPException(status_code=400, detail="–û—à–∏–±–∫–∞: –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ .md —Ñ–∞–π–ª.")

    try:
        content_bytes = await file.read()
        content_text = content_bytes.decode('utf-8')

        logger.info("[TECH KB] –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ...")
        enriched_content = duplicate_headers_without_hashes(content_text)
        logger.info("[TECH KB] –ó–∞–≥–æ–ª–æ–≤–∫–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã.")

        backup_dir = "kb/backups"
        os.makedirs(backup_dir, exist_ok=True)
        timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
        backup_path = os.path.join(backup_dir, f"knowledge_base2_{timestamp}.md.bak")
        if os.path.exists(kb_path):
            shutil.copy(kb_path, backup_path)
            logger.info(f"üíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø –¢–ï–• –ë–ó: {backup_path}")

        with open(kb_path, "w", encoding='utf-8') as buffer:
            buffer.write(enriched_content)

        logger.info(f"‚úÖ –ù–æ–≤—ã–π —Ñ–∞–π–ª –¢–ï–• –ë–ó '{file.filename}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.")

        asyncio.create_task(recreate_embeddings_and_reload_agent())

        return JSONResponse(status_code=202, content={"message": "–§–∞–π–ª –ø—Ä–∏–Ω—è—Ç. –ù–∞—á–∞–ª—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¢–ï–• –ë–ó. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¢–ï–• –ë–ó: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")

async def recreate_embeddings_and_reload_agent():
    logger.info("‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ...")
    loop = asyncio.get_event_loop()
    try:
        success = await loop.run_in_executor(None, recreate_embeddings)
        if success:
            logger.info("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω—ã.")
            if agent and hasattr(agent, 'reload'):
                agent.reload()
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ –ª–æ–≥–µ –≤—ã—à–µ.")

    except Exception as e:
        logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}", exc_info=True)


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, callerId: str = Query(None)):
    await websocket.accept()
    session_id = str(uuid.uuid4())
    start_time = datetime.now(timezone.utc)

    active_calls[session_id] = {
        "callerId": callerId,
        "startTime": start_time.isoformat(),
        "transcript": [],
        "status": "Initiated"
    }
    logger.info(f"–ù–æ–≤—ã–π –∑–≤–æ–Ω–æ–∫: Session ID: {session_id}, Caller ID: {callerId}")

    if not agent:
        await websocket.send_text("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞.")
        await websocket.close()
        del active_calls[session_id]
        return

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑ —Ñ–∞–π–ª–∞
        greeting = agent.prompts.get("greeting", "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, —á–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        active_calls[session_id]["transcript"].append(
            {"speaker": "bot", "text": greeting, "timestamp": datetime.now(timezone.utc).isoformat()}
        )
        await websocket.send_text(greeting)

        while True:
            data = await websocket.receive_text()
            norm = normalize_text(data)
            logger.info(f"–ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å ({session_id}) RAW='{data}' NORM='{norm}'")
            active_calls[session_id]["transcript"].append(
                {"speaker": "user", "text": norm, "raw": data, "timestamp": datetime.now(timezone.utc).isoformat()}
            )

            response_generator = agent.get_response_generator(norm, session_id=session_id)

            full_response = ""
            for chunk in response_generator:
                if chunk:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–µ–∂–Ω–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –≤—Ö–æ–¥–∞; –≤—ã—Ö–æ–¥ —à–ª—ë–º –∫–∞–∫ –µ—Å—Ç—å
                    await websocket.send_text(chunk)
                    full_response += chunk

            logger.info(f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç ({session_id}) –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.")
            kb_used = getattr(agent, 'last_kb', None)
            active_calls[session_id]["transcript"].append(
                {
                    "speaker": "bot",
                    "text": full_response,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "kb": kb_used,
                }
            )
            active_calls[session_id]["status"] = "InProgress"

    except WebSocketDisconnect:
        logger.info(f"–ö–ª–∏–µ–Ω—Ç ({session_id}) –æ—Ç–∫–ª—é—á–∏–ª—Å—è.")
        active_calls[session_id]["status"] = "Completed"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ WS ({session_id}): {e}", exc_info=True)
        active_calls[session_id]["status"] = "Failed"
    finally:
        # ... (–ª–æ–≥–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        end_time = datetime.now(timezone.utc)
        call_log = active_calls.get(session_id)
        if call_log:
            log_record: Dict[str, Any] = {
                "id": session_id,
                "callerId": call_log["callerId"],
                "startTime": call_log["startTime"],
                "endTime": end_time.isoformat(),
                "status": call_log["status"],
                "transcript": call_log["transcript"],
            }
            try:
                await insert_log(log_record)
                logger.info(f"üíæ –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –¥–ª—è Session {session_id}")
            except Exception as err:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ insert_log: {err}", exc_info=True)

            del active_calls[session_id]

___

scenario_barge-in_2.js
/**
 * asterisk-vox-bot -—Å—Ü–µ–Ω–∞—Ä–∏–π –¥–ª—è –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞ 
 * –í–µ—Ä—Å–∏—è 8.4.1 (—Å—Ç–∞–±–∏–ª—å–Ω–∞—è, —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –ª–æ–∂–Ω–æ–≥–æ barge-in)
 *
 * –û—Ç–ª–∏—á–∏—è: –≥–æ–≤–æ—Ä–∏–º —Ü–µ–ª—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ (–ø–æ '|'), –æ—á–µ—Ä–µ–¥—å TTS, –±–∞—Ä–≥–∏–Ω —á–∏—Å—Ç–∏—Ç –æ—á–µ—Ä–µ–¥—å.
 */

require(Modules.ASR);

// ‚îÄ‚îÄ‚îÄ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
const WS_URL = "ws://31.207.75.71:9000/ws";
const VOICE = VoiceList.TBank.ru_RU_Alyona;

const SPEECH_END_TIMEOUT = 200;   // —Å—Ç—Ä–∞—Ö–æ–≤–∫–∞: –æ–∑–≤—É—á–∏—Ç—å —Ö–≤–æ—Å—Ç –±–µ–∑ '|', –º—Å
const DEBOUNCE_TIMEOUT   = 700;   // –∑–∞—â–∏—Ç–∞ –æ—Ç —ç—Ö–∞ —Å—Ä–∞–∑—É –ø–æ—Å–ª–µ —Å—Ç–∞—Ä—Ç–∞ TTS, –º—Å
const BARGE_IN_GUARD_MS  = 400;   // –∏–≥–Ω–æ—Ä –±–∞—Ä–≥–∏–Ω–∞ –ø–µ—Ä–≤—ã–µ N –º—Å
const INPUT_DEBOUNCE_MS  = 1200;  // —Ç–∏—à–∏–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è = –∫–æ–Ω–µ—Ü —Ä–µ–ø–ª–∏–∫–∏, –º—Å
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

// ‚îÄ‚îÄ‚îÄ –≥–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
let call, asr, wsReady = false;

// –±—É—Ñ–µ—Ä –æ—Ç –±—ç–∫–µ–Ω–¥–∞ (–æ—Ç–≤–µ—Ç –±–æ—Ç–∞ ‚Üí –¥–ª—è TTS)
let buf = "";
let bufTimer = null;

// –±—É—Ñ–µ—Ä —Ä–µ—á–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è (ASR)
let utterBuf = "";
let utterTimer = null;
let lastUtter = "";

// TTS
let currentPlayer = null;
let isSpeaking = false;
let lastSpeakStartedAt = 0;

// –æ—á–µ—Ä–µ–¥—å TTS
let ttsQueue = [];
let ttsBusy  = false;
// ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ

function clean(txt) {
  // –ú–æ–∂–Ω–æ –≤ –∫–æ–Ω—Ü–µ –¥–æ–±–∞–≤–∏—Ç—å —Ç–æ—á–∫—É, –µ—Å–ª–∏ —Ö–æ—Ç–∏—Ç–µ —á—ë—Ç—á–µ –∫–∞–¥–µ–Ω—Å:
  // if (s && !/[.!?‚Ä¶]$/.test(s)) s += ".";
  return String(txt).replace(/[|*]/g, " ").replace(/\s+/g, " ").trim();
}

VoxEngine.addEventListener(AppEvents.CallAlerting, function (ev) {
  call = ev.call;
  Logger.write("üöÄ start, callId=" + call.id);
  call.answer();

  // 1) ASR
  const HINTS_EXTRA = [
    "–∫–ù","–∫–Ω","–∫–∏–ª–æ–Ω—å—é—Ç–æ–Ω","–∫–∏–ª–æ–Ω—å—é—Ç–æ–Ω—ã","–∫–∏–ª–æ–Ω—å—é—Ç–æ–Ω–∞","–∫–∞-—ç–Ω","–∫—ç-—ç–Ω","–∫ —ç–Ω","–∫ —ç–ù","–∫—ç–Ω",
    "–ù","–Ω—å—é—Ç–æ–Ω","–Ω—å—é—Ç–æ–Ω–æ–≤","–Ω—å—é—Ç–æ–Ω–µ",
    "–ù¬∑–º","–Ω—å—é—Ç–æ–Ω-–º–µ—Ç—Ä","–Ω—å—é—Ç–æ–Ω –º–µ—Ç—Ä","–Ω –º",
    "–ù¬∑–º–º","–Ω—å—é—Ç–æ–Ω –º–∏–ª–ª–∏–º–µ—Ç—Ä","–Ω –º–º",
    "–ú–ü–∞","–º–ø–∞","–º—ç-–ø—ç-–∞","—ç–º-–ø—ç-–∞","–º–µ–≥–∞ –ø–∞—Å–∫–∞–ª—å","–º–µ–≥–∞–ø–∞—Å–∫–∞–ª—å",
    "–∫–ü–∞","–∫–ø–∞","–∫—ç-–ø—ç-–∞","–∫–∏–ª–æ–ø–∞—Å–∫–∞–ª—å","–∫–∏–ª–æ –ø–∞—Å–∫–∞–ª—å","–ø–∞—Å–∫–∞–ª—å","–ü–∞",
    "–ù/–º–º¬≤","–Ω—å—é—Ç–æ–Ω –Ω–∞ –º–∏–ª–ª–∏–º–µ—Ç—Ä –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π","–Ω –Ω–∞ –º–º2","–Ω/–º–º2",
    "–ì—Ü","–≥–µ—Ä—Ü","—á–∞—Å—Ç–æ—Ç–∞ –≤ –≥–µ—Ä—Ü–∞—Ö",
    "–º–º","–º–∏–ª–ª–∏–º–µ—Ç—Ä","–º–∏–ª–ª–∏–º–µ—Ç—Ä—ã","–º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤","mm",
    "—Å–º","—Å–∞–Ω—Ç–∏–º–µ—Ç—Ä","—Å–∞–Ω—Ç–∏–º–µ—Ç—Ä—ã","—Å–∞–Ω—Ç–∏–º–µ—Ç—Ä–æ–≤","cm",
    "–º","–º–µ—Ç—Ä","–º–µ—Ç—Ä—ã","–º–µ—Ç—Ä–æ–≤",
    "–º–º/–º–∏–Ω","–º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤ –≤ –º–∏–Ω—É—Ç—É","–º–º –≤ –º–∏–Ω—É—Ç—É",
    "–º–º/—Å","–º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É","–º–º –≤ —Å–µ–∫—É–Ω–¥—É",
    "–º/—Å","–º–µ—Ç—Ä–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É",
    "–æ–±/–º–∏–Ω","rpm","–æ–± –≤ –º–∏–Ω—É—Ç—É",
    "–∫–≥","–∫–∏–ª–æ–≥—Ä–∞–º–º","–∫–∏–ª–æ–≥—Ä–∞–º–º–∞","–∫–∏–ª–æ–≥—Ä–∞–º–º—ã","kg",
    "–≥—Ä–∞–º–º","–≥—Ä–∞–º–º–∞","–≥—Ä–∞–º–º—ã",
    "—Ç","—Ç–æ–Ω–Ω–∞","—Ç–æ–Ω–Ω—ã",
    "%","–ø—Ä–æ—Ü–µ–Ω—Ç—ã","–ø—Ä–æ—Ü–µ–Ω—Ç",
    "–ª/–º–∏–Ω","–ª–∏—Ç—Ä –≤ –º–∏–Ω—É—Ç—É","–ª–∏—Ç—Ä–æ–≤ –≤ –º–∏–Ω—É—Ç—É","l/min",
    "–±–∞—Ä","bar","–∫–≥—Å/—Å–º¬≤","–∫–∏–ª–æ–≥—Ä–∞–º–º —Å–∏–ª—ã –Ω–∞ —Å–∞–Ω—Ç–∏–º–µ—Ç—Ä –∫–≤–∞–¥—Ä–∞—Ç–Ω—ã–π",
    "–í—Ç","–≤–∞—Ç—Ç","w","–∫–í—Ç","–∫–≤—Ç","–∫–∏–ª–æ–≤–∞—Ç—Ç","kw","–∫–í—Ç¬∑—á","–∫–≤—Ç—á","–∫–∏–ª–æ–≤–∞—Ç—Ç —á–∞—Å",
    "–í","–≤–æ–ª—å—Ç","v","–ê","–∞–º–ø–µ—Ä","amp","–û–º","–æ–º—ã","ohm","Œ©",
    "–¥–ë","–¥–µ—Ü–∏–±–µ–ª","db",
    "–º–∏–Ω/—á","–º–∏–Ω—É—Ç –≤ —á–∞—Å","–º–∏–Ω –Ω–∞ —á–∞—Å",
    "ISO 7500-1","ASTM E4","ISO 6892-1","ASTM E8","ASTM E9",
  ];

  asr = VoxEngine.createASR({
    profile: ASRProfileList.TBank.ru_RU,
    interimResults: true,
    phraseHints: [
      "—Ç–≤–µ—Ä–¥–æ–º–µ—Ä","—Ç–≤–µ—Ä–¥–æ–º–µ—Ä—ã","—Ç–≤–µ—Ä–¥–æ–º–µ—Ä –†–æ–∫–≤–µ–ª–ª–∞","—Ç–≤–µ—Ä–¥–æ–º–µ—Ä –ë—Ä–∏–Ω–µ–ª–ª—è","—Ç–≤–µ—Ä–¥–æ–º–µ—Ä –í–∏–∫–∫–µ—Ä—Å–∞","–º–∏–∫—Ä–æ—Ç–≤–µ—Ä–¥–æ–º–µ—Ä",
      "—Ä–∞–∑—Ä—ã–≤–Ω–∞—è –º–∞—à–∏–Ω–∞","—Ä–∞–∑—Ä—ã–≤–Ω—ã–µ –º–∞—à–∏–Ω—ã","–∏—Å–ø—ã—Ç–∞—Ç–µ–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞","–∏—Å–ø—ã—Ç–∞—Ç–µ–ª—å–Ω—ã–µ –º–∞—à–∏–Ω—ã","—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è —Ä–∞–∑—Ä—ã–≤–Ω–∞—è –º–∞—à–∏–Ω–∞",
      "–∏—Å–ø—ã—Ç–∞—Ç–µ–ª—å–Ω—ã–π –ø—Ä–µ—Å—Å","–∏—Å–ø—ã—Ç–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–µ—Å—Å—ã","–ø—Ä–µ—Å—Å –ü–ò",
      "–†–ì–ú","–†–ì–ú-1000","–†–ì–ú-1000-–ê",
      "–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –º–∞—à–∏–Ω–∞","—É—Å—Ç–∞–ª–æ—Å—Ç–Ω–∞—è –º–∞—à–∏–Ω–∞",
      "–∏—Å–ø—ã—Ç–∞–Ω–∏–µ –Ω–∞ —Ä–∞—Å—Ç—è–∂–µ–Ω–∏–µ","–∏—Å–ø—ã—Ç–∞–Ω–∏–µ –Ω–∞ —Å–∂–∞—Ç–∏–µ","–∏—Å–ø—ã—Ç–∞–Ω–∏–µ –Ω–∞ –∏–∑–≥–∏–±","–ú–µ—Ç—Ä–æ—Ç—ç—Å—Ç",
      "–†–ì–ú-–ì-–ê","–†–≠–ú","–†–≠–ú-I-0,1","–†–≠–ú-1","–†–≠–ú-50","–†–≠–ú-100","–†–≠–ú-200","–†–≠–ú-300","–†–≠–ú-500","–†–≠–ú-600",
      "–†–≠–ú-I-2","–†–≠–ú-I-3","–†–≠–ú-I-5","–†–≠–ú-I-10",
      "–£–ò–ú-–î","–£–ò–ú-–î-100","–£–ò–ú-–î-250","–£–ò–ú-–î-500","–£–ò–ú-–î-750","–ø–Ω–µ–≤–º–æ–¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∞—è –º–∞—à–∏–Ω–∞",
      "–ü–ò–ú-–ú–†-100","–ü–ò–ú-–ú–†-200","–ü–ò–ú-–ú–†-300",
      "—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–µ –∏—Å–ø—ã—Ç–∞—Ç–µ–ª—å–Ω—ã–µ –º–∞—à–∏–Ω—ã","—É–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω–∞—è –º–∞—à–∏–Ω–∞",
      "–º–∞—à–∏–Ω–∞ –Ω–∞ —É—Å—Ç–∞–ª–æ—Å—Ç—å","—É—Å—Ç–∞–ª–æ—Å—Ç–Ω—ã–µ –∏—Å–ø—ã—Ç–∞–Ω–∏—è",
      "–º–∞—à–∏–Ω—ã –Ω–∞ –∫—Ä—É—á–µ–Ω–∏–µ","–º–∞—à–∏–Ω—ã –Ω–∞ –∏–∑–≥–∏–±",
      "–ú–ö","–ú–ö–°","–ú–ö–°-1000","–ú–ö–°-2000","–ú–ö–°-3000","–ú–ö–°-500",
      "—Å–∏—Å—Ç–µ–º—ã —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–Ω—ã—Ö –∏—Å–ø—ã—Ç–∞–Ω–∏–π","–°–¢–ò",
      "—ç–∫—Å—Ç–µ–Ω–∑–æ–º–µ—Ç—Ä","–£–ò–î-–ü–ë","M-VIEW",
      "–∫–æ–ø—Ä–∞ –º–∞—è—Ç–Ω–∏–∫–æ–≤–∞—è","–∫–æ–ø—Ä—ã","–ö–ú","–ö–í","–ö–ú–ú","–ò–ö–ú-450-–ê",
      "—Å—Ç–∏–ª–æ—Å–∫–æ–ø","–°–õ–ü","–°–õ-13–£","–°–õ-15",
      "–∫–ª–∏–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –∫–∞–º–µ—Ä—ã","–ö–¢–•","–ö–ò–û","–ö–ò–£","–ö–¢–í","–ö–¢–ó","–ö–¢–ß",
      "—Ä–µ—Å—É—Ä—Å–Ω–æ–µ –∏—Å–ø—ã—Ç–∞–Ω–∏–µ","–∏—Å–ø—ã—Ç–∞–Ω–∏–µ –Ω–∞ –∏–∑–Ω–æ—Å",
      "–º–∞—à–∏–Ω—ã —à–ª–∏—Ñ–æ–≤–∞–ª—å–Ω–æ-–ø–æ–ª–∏—Ä–æ–≤–∞–ª—å–Ω—ã–µ","–ú–®–ü","–ú–ü",
      "–º–∏–∫—Ä–æ—Å–∫–æ–ø –º–µ—Ç–∞–ª–ª–æ–≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏–π","–ú–ú–ò","–ú–ú–†","–ú–ú–ü",
      "–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è –º–æ–¥—É–ª—å–Ω–∞—è","–õ–ú–ú-25",
      "–º–µ–±–µ–ª—å –ª–∞–±–æ—Ä–∞—Ç–æ—Ä–Ω–∞—è","–°–ö–ó-1","–°–ö–ó-2","–°–ö–ó-3-–ê","–°–ö–ó-4"
    ].concat(HINTS_EXTRA)
  });

  // –±–∞—Ä–≥–∏–Ω: –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º/–æ—Ç–º–µ–Ω—è–µ–º TTS –∏ –æ—á–µ—Ä–µ–¥—å (–µ—Å–ª–∏ –Ω–µ —Å–ª–∏—à–∫–æ–º —Ä–∞–Ω–æ)
  const stopPlayerOnBargeIn = (eventName) => {
    const sinceStart = Date.now() - lastSpeakStartedAt;
    if (currentPlayer && sinceStart < BARGE_IN_GUARD_MS) {
      // —Å–ª–∏—à–∫–æ–º —Ä–∞–Ω–æ ‚Äî –≤–µ—Ä–æ—è—Ç–Ω–æ–µ —ç—Ö–æ; –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º
      return;
    }
    Logger.write(`[BARGE-IN] '${eventName}' ‚Üí cancel TTS (sinceStart=${sinceStart}ms).`);
    if (currentPlayer) {
      try { currentPlayer.stop(); } catch (e) {}
      currentPlayer = null;
    }
    isSpeaking = false;
    // –æ—á–∏—â–∞–µ–º –æ—á–µ—Ä–µ–¥—å, —á—Ç–æ–±—ã –Ω–µ –¥–æ–≥–æ–≤–∞—Ä–∏–≤–∞—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–µ–µ
    if (ttsQueue.length) {
      ttsQueue = [];
      ttsBusy  = false;
    }
  };

  // –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ –ø–æ–¥–ø–∏—Å–∫–∏ –Ω–∞ —Å–æ–±—ã—Ç–∏—è ASR (—Ä–∞–∑–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—Ç —Ä–∞–∑–Ω—ã–π –Ω–∞–±–æ—Ä)
  function hasASREvent(name) {
    return typeof ASREvents !== 'undefined' && ASREvents && typeof ASREvents[name] !== 'undefined';
  }
  if (hasASREvent('CaptureStarted')) {
    asr.addEventListener(ASREvents.CaptureStarted, () => stopPlayerOnBargeIn('CaptureStarted'));
  }
  if (hasASREvent('InterimResult')) {
    asr.addEventListener(ASREvents.InterimResult, () => stopPlayerOnBargeIn('InterimResult'));
  }

  // –ë—ã—Å—Ç—Ä—ã–π —Ñ–ª–∞—à –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π —Ä–µ–ø–ª–∏–∫–∏ –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏—é –∑–∞—Ö–≤–∞—Ç–∞ —Ä–µ—á–∏
  function flushUserUtterance(reason) {
    if (!utterBuf) return;
    if (utterTimer) { clearTimeout(utterTimer); utterTimer = null; }
    const normalizedReady = normalizeUtterance(utterBuf.trim());
    Logger.write(`üó£Ô∏è RAW(${reason}): ` + utterBuf);
    if (normalizedReady && wsReady && normalizedReady !== lastUtter && isInformative(normalizedReady)) {
      Logger.write("üß≠ NORM SEND: " + normalizedReady);
      socket.send(normalizedReady);
      lastUtter = normalizedReady;
    } else {
      Logger.write("‚è≥ skipped non-informative user chunk");
    }
    utterBuf = "";
    // –µ—Å–ª–∏ –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç —à—ë–ª –Ω–∞–±–æ—Ä –æ—Ç–≤–µ—Ç–∞ ‚Äî –æ–±–Ω—É–ª–∏–º –µ–≥–æ, —á—Ç–æ–±—ã –Ω–µ —Å–º–µ—à–∏–≤–∞—Ç—å
    if (bufTimer) { clearTimeout(bufTimer); bufTimer = null; buf = ""; }
  }

  if (hasASREvent('CaptureStopped')) {
    asr.addEventListener(ASREvents.CaptureStopped, function () {
      flushUserUtterance('CaptureStopped');
    });
  }

  // –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
  function normalizeUtterance(input) {
    if (!input) return input;
    let t = input;
    t = t.replace(/[‚Äì‚Äî‚àí]/g, "-").replace(/\s+/g, " ");

    t = t.replace(/\b(—Ä—ç–º|—Ä–µ–º|—Ä–µ–Ω)\b/gi, "–†–≠–ú");
    t = t.replace(/\b(—Ä–≥–º|—ç—Ä–≥—ç–º)\b/gi, "–†–ì–ú");
    t = t.replace(/\b(—Å—Ç–∏–ª–æ—Å?–∫–æ–ø|—Å—Ç–µ–ª–æ—Å–∫–æ–ø|—Å—Ç–∏–ª–æ—Å–∫–∞?–ø|—Ñ–∏–ª–æ—Å\w*|—Ñ–∏–ª–æ—Å–∫–æ–ø)\b/gi, "—Å—Ç–∏–ª–æ—Å–∫–æ–ø");

    t = t.replace(/\b(–∫\s?—ç–Ω|–∫–∞-—ç–Ω|–∫—ç-—ç–Ω|–∫\s?–µ–Ω|–∫\s?—ç\s?–Ω|–∫—ç–Ω)\b/gi, "–∫–ù");
    t = t.replace(/\b–∫–∏–ª–æ\s?–Ω—å—é—Ç–æ–Ω—ã?\b/gi, "–∫–ù");
    t = t.replace(/\b–∫–Ω\b/gi, "–∫–ù");

    t = t.replace(/\b(–º\s?–ø\s?–∞|–º—ç-–ø—ç-–∞|—ç–º-–ø—ç-–∞|–º–µ–≥–∞–ø–∞—Å–∫–∞–ª[—å—è–µ—ã]?|–º–µ–≥–∞\s?–ø–∞—Å–∫–∞–ª[—å—è–µ—ã]?)\b/gi, "–ú–ü–∞");
    t = t.replace(/\b(–∫\s?–ø\s?–∞|–∫—ç-–ø—ç-–∞|–∫–∏–ª–æ–ø–∞—Å–∫–∞–ª[—å—è–µ—ã]?|–∫–∏–ª–æ\s?–ø–∞—Å–∫–∞–ª[—å—è–µ—ã]?)\b/gi, "–∫–ü–∞");
    t = t.replace(/\b(–≥–µ—Ä—Ü|–≥–µ—Ä—Ü—ã|–≥—Ü)\b/gi, "–ì—Ü");

    t = t.replace(/\b–Ω—å—é—Ç–æ–Ω[–∞-—è]*\b/gi, "–ù");
    t = t.replace(/\b(–Ω—å—é—Ç–æ[–Ω–Ω][ -]?–º–µ—Ç—Ä[–∞-—è]*|–Ω\s?–º)\b/gi, "–ù¬∑–º");
    t = t.replace(/\b(–Ω—å—é—Ç–æ[–Ω–Ω][ -]?–º–∏–ª–ª–∏–º–µ—Ç—Ä[–∞-—è]*|–Ω\s?–º–º)\b/gi, "–ù¬∑–º–º");
    t = t.replace(/\b(–Ω(—å?—é—Ç–æ–Ω)?\s*(?:\/|–Ω–∞)\s*–º–º\s*(?:\^?2|¬≤)|–Ω—å—é—Ç–æ–Ω\s+–Ω–∞\s+–º–∏–ª–ª–∏–º–µ—Ç—Ä\s+–∫–≤–∞–¥—Ä–∞—Ç–Ω[–∞-—è]*)\b/gi, "–ù/–º–º¬≤");

    t = t.replace(/\b–º–∏–ª–ª–∏–º–µ—Ç—Ä[–∞-—è]*\b/gi, "–º–º");
    t = t.replace(/\bmm\b/gi, "–º–º");
    t = t.replace(/\b—Å–∞–Ω—Ç–∏–º–µ—Ç—Ä[–∞-—è]*\b/gi, "—Å–º");
    t = t.replace(/\bcm\b/gi, "—Å–º");
    t = t.replace(/\b–º–µ—Ç—Ä[–∞-—è]*\b/gi, "–º");

    t = t.replace(/\b(–º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤\s+–≤\s+–º–∏–Ω—É—Ç—É|–º–º\s+–≤\s+–º–∏–Ω—É—Ç—É)\b/gi, "–º–º/–º–∏–Ω");
    t = t.replace(/\b(–º–∏–ª–ª–∏–º–µ—Ç—Ä–æ–≤\s+–≤\s+—Å–µ–∫—É–Ω–¥—É|–º–º\s+–≤\s+—Å–µ–∫—É–Ω–¥—É|–º–º\/—Å)\b/gi, "–º–º/—Å");
    t = t.replace(/\b(–º–µ—Ç—Ä–æ–≤\s+–≤\s+—Å–µ–∫—É–Ω–¥—É)\b/gi, "–º/—Å");
    t = t.replace(/\b(r\s?p\s?m|–æ–±–æ—Ä–æ—Ç–æ–≤?\s+–≤\s+–º–∏–Ω—É—Ç—É|–æ–±\/?–º–∏–Ω)\b/gi, "–æ–±/–º–∏–Ω");

    t = t.replace(/\b–∫–∏–ª–æ–≥—Ä–∞–º–º[–∞-—è]*\b/gi, "–∫–≥");
    t = t.replace(/\bkg\b/gi, "–∫–≥");
    t = t.replace(/\b–≥—Ä–∞–º–º[–∞-—è]*\b/gi, "–≥");
    t = t.replace(/\b—Ç–æ–Ω–Ω[–∞-—è]*\b/gi, "—Ç");

    t = t.replace(/\b–≥—Ä–∞–¥—É—Å(–æ–≤)?\s+—Ü–µ–ª—å—Å–∏—è\b/gi, "¬∞C");
    t = t.replace(/\b–ø–æ\s+—Ü–µ–ª—å—Å–∏—é\b/gi, "¬∞C");
    t = t.replace(/\b–ø—Ä–æ—Ü–µ–Ω—Ç(–æ–≤)?\b/gi, "%");

    t = t.replace(/\b(–≤–∞—Ç—Ç(–∞|–æ–≤)?|w)\b/gi, "–í—Ç");
    t = t.replace(/\b(–∫–∏–ª–æ–≤–∞—Ç—Ç(–∞|–æ–≤)?|–∫\s?–≤—Ç|kw)\b/gi, "–∫–í—Ç");
    t = t.replace(/\b(–∫–í—Ç\s*[¬∑xx]\s*—á|–∫–∏–ª–æ–≤–∞—Ç—Ç\s*—á–∞—Å[–∞-—è]*|–∫–≤—Ç—á)\b/gi, "–∫–í—Ç¬∑—á");
    t = t.replace(/\b(–≤–æ–ª—å—Ç(–∞|–æ–≤)?|v)\b/gi, "–í");
    t = t.replace(/\b(–∞–º–ø–µ—Ä(–∞|–æ–≤)?|amp(?:s)?)\b/gi, "–ê");
    t = t.replace(/\b(–æ–º(–∞|–æ–≤)?|ohm|Œ©)\b/gi, "–û–º");

    t = t.replace(/\b(–ª–∏—Ç—Ä(–æ–≤)?\s*–≤\s*–º–∏–Ω—É—Ç—É|–ª\/?–º–∏–Ω|l\/?min)\b/gi, "–ª/–º–∏–Ω");
    t = t.replace(/\b(–±–∞—Ä|bar)\b/gi, "–±–∞—Ä");
    t = t.replace(/\b(–∫–≥—Å\s*\/\s*—Å–º\s*(?:\^?2|¬≤)|–∫–∏–ª–æ–≥—Ä–∞–º–º\s*—Å–∏–ª—ã\s*–Ω–∞\s*—Å–∞–Ω—Ç–∏–º–µ—Ç—Ä\s*–∫–≤–∞–¥—Ä–∞—Ç–Ω[–∞-—è]*)\b/gi, "–∫–≥—Å/—Å–º¬≤");

    t = t.replace(/\b(–¥–µ—Ü–∏–±–µ–ª(–∞|–æ–≤)?|–¥–±|db)\b/gi, "–¥–ë");
    t = t.replace(/\s+\/\s+/g, "/");

    return t.trim();
  }

  function isInformative(text) {
    if (!text) return false;
    const trimmed = text.trim().toLowerCase();
    const fillers = ["–¥–∞","–∞–≥–∞","—É–≥—É","–Ω—É","–æ–∫","–æ–∫–µ–π","—Ö–æ—Ä–æ—à–æ","–ø–æ–Ω—è—Ç–Ω–æ","–æ","—É–≥—É-—É–≥—É"];
    if (trimmed.length <= 2) return false;
    if (fillers.includes(trimmed)) return false;
    if (/[0-9]/.test(trimmed)) return true;
    if (/(–∫–Ω|–º–ø–∞|–º–º\/—Å|–º–º\/–º–∏–Ω|–≥—Ü|iso|astm|–≥–æ—Å—Ç|—Ä–≥–º|—Ä—ç–º|—Å—Ç–∏–ª–æ—Å–∫–æ–ø|–∞—Ä–º–∞—Ç—É—Ä|—Ç–≤–µ—Ä–¥–æ–º–µ—Ä)/i.test(trimmed)) return true;
    return trimmed.split(/\s+/).length >= 3;
  }

  asr.addEventListener(ASREvents.Result, function (e) {
    if (!e.text) return;

    // –∞–∫–∫—É—Ä–∞—Ç–Ω–æ —Å–æ–±–∏—Ä–∞–µ–º —Ä–∞—Å—Ç—É—â–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    const txt = e.text.trim();
    if (!utterBuf) {
      utterBuf = txt;
    } else if (txt.startsWith(utterBuf)) {
      utterBuf = txt; // —Ä–∞—Å—Ç—ë—Ç
    } else if (!utterBuf.startsWith(txt)) {
      utterBuf = (utterBuf + " " + txt).replace(/\s+/g, " ").trim();
    }

    if (utterTimer) clearTimeout(utterTimer);
    utterTimer = setTimeout(function () {
      const normalizedReady = normalizeUtterance(utterBuf.trim());
      Logger.write("üó£Ô∏è RAW: " + utterBuf);
      if (normalizedReady && wsReady && normalizedReady !== lastUtter && isInformative(normalizedReady)) {
        Logger.write("üß≠ NORM SEND: " + normalizedReady);
        socket.send(normalizedReady);
        lastUtter = normalizedReady;
      } else {
        Logger.write("‚è≥ skipped non-informative user chunk");
      }
      utterBuf = "";
      utterTimer = null;

      // –µ—Å–ª–∏ –≤ —ç—Ç–æ—Ç –º–æ–º–µ–Ω—Ç —à—ë–ª –Ω–∞–±–æ—Ä –æ—Ç–≤–µ—Ç–∞ ‚Äî –æ–±–Ω—É–ª–∏–º –µ–≥–æ, —á—Ç–æ–±—ã –Ω–µ —Å–º–µ—à–∏–≤–∞—Ç—å
      if (bufTimer) { clearTimeout(bufTimer); bufTimer = null; buf = ""; }
    }, INPUT_DEBOUNCE_MS);
  });

  // 2) –ø–æ–¥–∫–ª—é—á–∞–µ–º –≤—Ö–æ–¥—è—â–∏–π –∑–≤—É–∫ –∫ ASR
  call.sendMediaTo(asr);

  // 3) WebSocket –∫ –±—ç–∫–µ–Ω–¥—É
  const callerId = call.callerid();
  const urlWithCallerId = `${WS_URL}?callerId=${encodeURIComponent(callerId)}`;
  const socket = VoxEngine.createWebSocket(urlWithCallerId);

  socket.addEventListener(WebSocketEvents.OPEN, function () {
    wsReady = true;
    Logger.write(`‚úÖ WS open for ${callerId}.`);
  });

  // –ì–æ–≤–æ—Ä–∏–º —Ç–æ–ª—å–∫–æ —Ü–µ–ª—ã–º–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –ø–æ —Å–∏–º–≤–æ–ª—É '|'
  socket.addEventListener(WebSocketEvents.MESSAGE, function (m) {
    if (!m.text) return;

    buf += m.text;

    // 1) –≤—ã–≥–æ–≤–æ—Ä–∏–º –≤—Å–µ –∑–∞–≤–µ—Ä—à—ë–Ω–Ω—ã–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
    while (buf.includes("|")) {
      const idx = buf.indexOf("|");
      const sentence = clean(buf.slice(0, idx));
      buf = buf.slice(idx + 1);
      if (sentence) speakQueued(sentence);
    }

    // 2) –µ—Å–ª–∏ –æ—Å—Ç–∞–ª—Å—è ¬´—Ö–≤–æ—Å—Ç¬ª –±–µ–∑ '|', –∑–∞–≤–µ–¥—ë–º —Å—Ç—Ä–∞—Ö–æ–≤–æ—á–Ω—ã–π —Ç–∞–π–º–µ—Ä
    if (bufTimer) clearTimeout(bufTimer);
    if (buf) {
      bufTimer = setTimeout(function () {
        const tail = clean(buf);
        buf = "";
        bufTimer = null;
        if (tail) speakQueued(tail);
      }, SPEECH_END_TIMEOUT);
    } else {
      bufTimer = null;
    }
  });

  socket.addEventListener(WebSocketEvents.ERROR, function (e) {
    Logger.write("‚ùå WS error:" + JSON.stringify(e));
  });

  socket.addEventListener(WebSocketEvents.CLOSE, function () {
    Logger.write("üîå WS close.");
    wsReady = false;
  });

  // 4) –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–≤–æ–Ω–∫–∞
  call.addEventListener(CallEvents.Disconnected, function () {
    Logger.write("üì¥ hang-up.");
    VoxEngine.terminate();
  });
});

// ‚îÄ‚îÄ‚îÄ –û—á–µ—Ä–µ–¥—å TTS ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
function speakQueued(text) {
  if (!text) return;
  ttsQueue.push(text);
  if (!ttsBusy) processTTSQueue();
}

function processTTSQueue() {
  if (ttsBusy) return;
  const next = ttsQueue.shift();
  if (!next) return;

  ttsBusy = true;
  speakOne(next, function () {
    ttsBusy = false;
    processTTSQueue();
  });
}

/* –ü—Ä–æ–∏–≥—Ä–∞—Ç—å –æ–¥–Ω—É —Ñ—Ä–∞–∑—É */
function speakOne(text, done) {
  Logger.write(`‚ñ∂Ô∏è TTS: "${text}"`);

  if (currentPlayer) {
    try { currentPlayer.stop(); } catch (e) {}
    currentPlayer = null;
  }

  isSpeaking = true;
  lastSpeakStartedAt = Date.now();
  setTimeout(() => { isSpeaking = false; }, DEBOUNCE_TIMEOUT);

  currentPlayer = VoxEngine.createTTSPlayer(text, {
    language: VOICE,
    progressivePlayback: true // —Ñ—Ä–∞–∑–∞ —É–∂–µ —Ü–µ–ª–∏–∫–æ–º ‚Üí –ø—Ä–æ—Å–æ–¥–∏—è —Ä–æ–≤–Ω–∞—è
  });
  currentPlayer.sendMediaTo(call);

  const finish = () => {
    currentPlayer = null;
    if (typeof done === "function") done();
  };

  currentPlayer.addEventListener(PlayerEvents.PlaybackFinished, finish);
  currentPlayer.addEventListener(PlayerEvents.Stopped,          finish);
}
