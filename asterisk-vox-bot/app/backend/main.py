"""
–û—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è.
- WebSocket-—Å–µ—Ä–≤–µ—Ä –¥–ª—è –æ–±—â–µ–Ω–∏—è —Å Voximplant
- API –¥–ª—è –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ –ª–æ–≥–æ–≤
- –°—Ç–∞—Ç–∏–∫–∞ –¥–ª—è UI –ª–æ–≥–æ–≤
"""
import os, logging, uuid, json, asyncio, io, shutil, time, re
from logging.handlers import RotatingFileHandler
from datetime import datetime, timezone
from typing import Dict, Any

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, Query, status, UploadFile, File, Depends, HTTPException, Security
from fastapi.security import APIKeyHeader
from fastapi.responses import HTMLResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field
from dotenv import load_dotenv

import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', '..'))

from app.backend.rag.agent import Agent
from app.backend.utils.text_normalizer import normalize as normalize_text
from app.backend.services.log_storage import insert_log, query_logs, to_csv, delete_all_logs
from scripts.create_embeddings import recreate_embeddings

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ---
load_dotenv()

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è ---
# –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –ª–æ–≥–æ–≤, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
os.makedirs("data/logs", exist_ok=True)
log_formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
log_file = "data/logs/app.log"

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —Ä–æ—Ç–∏—Ä—É–µ–º—ã–π —Ñ–∞–π–ª–æ–≤—ã–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫
file_handler = RotatingFileHandler(log_file, maxBytes=5*1024*1024, backupCount=5, encoding='utf-8')
file_handler.setFormatter(log_formatter)
file_handler.setLevel(logging.INFO)

# –ü–æ–ª—É—á–∞–µ–º –∫–æ—Ä–Ω–µ–≤–æ–π –ª–æ–≥–≥–µ—Ä –∏ –î–û–ë–ê–í–õ–Ø–ï–ú –Ω–∞—à –æ–±—Ä–∞–±–æ—Ç—á–∏–∫, –Ω–µ —É–¥–∞–ª—è—è —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ.
# –≠—Ç–æ –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã —Å –ª–æ–≥–≥–µ—Ä–∞–º–∏ Gunicorn/Uvicorn.
root_logger = logging.getLogger()
root_logger.addHandler(file_handler)
root_logger.setLevel(logging.INFO)

logger = logging.getLogger(__name__)


app = FastAPI()
app.mount("/logs-ui", StaticFiles(directory="app/frontend/logs-ui", html=True), name="logs-ui")


# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ ---

def duplicate_headers_without_hashes(text: str) -> str:
    """
    –î—É–±–ª–∏—Ä—É–µ—Ç –∑–∞–≥–æ–ª–æ–≤–∫–∏ Markdown (–æ—Ç h1 –¥–æ h6) –≤ —Ç–µ–∫—Å—Ç–µ,
    –¥–æ–±–∞–≤–ª—è—è –≤–µ—Ä—Å–∏—é –±–µ–∑ —Ö—ç—à–µ–π –≤ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–æ–∫–µ.
    """
    def replacer(match):
        header_line = match.group(0)
        clean_header = header_line.lstrip('#').strip()
        return f"{header_line}\n{clean_header}"

    processed_text = re.sub(r"^(#{1,6}\s.+)", replacer, text, flags=re.MULTILINE)
    return processed_text


def _update_env_file(vars_to_set: Dict[str, str]) -> None:
    env_path = os.path.join(os.getcwd(), ".env")
    lines: list[str] = []
    if os.path.exists(env_path):
        with open(env_path, "r", encoding="utf-8") as f:
            lines = f.read().splitlines()
    keys = set(vars_to_set.keys())
    new_lines: list[str] = []
    for line in lines:
        if not line or line.strip().startswith("#"):
            new_lines.append(line)
            continue
        key = line.split("=", 1)[0].strip()
        if key in keys:
            new_lines.append(f"{key}={vars_to_set[key]}")
            keys.remove(key)
        else:
            new_lines.append(line)
    for k in keys:
        new_lines.append(f"{k}={vars_to_set[k]}")
    with open(env_path, "w", encoding="utf-8") as f:
        f.write("\n".join(new_lines) + "\n")


# --- –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö (Pydantic) ---

class PromptsUpdatePayload(BaseModel):
    """–°—Ö–µ–º–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –≤—Ö–æ–¥—è—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –ø—Ä–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø—Ä–æ–º–ø—Ç–æ–≤."""
    greeting: str = Field(..., min_length=1, description="–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –±–æ—Ç–∞.")
    contextualize_q_system_prompt: str = Field(..., min_length=1, description="–°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∞—Ü–∏–∏.")
    qa_system_prompt: str = Field(..., min_length=1, description="–û—Å–Ω–æ–≤–Ω–æ–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã.")

class SearchSettingsPayload(BaseModel):
    kb_top_k: int | None = Field(None, ge=1, le=20)
    kb_fallback_threshold: float | None = Field(None, ge=0.0, le=1.0)

class ModelSettingsPayload(BaseModel):
    llm_model_primary: str | None = Field(None, description="–ò–º—è –æ—Å–Ω–æ–≤–Ω–æ–π –º–æ–¥–µ–ª–∏, –Ω–∞–ø—Ä–∏–º–µ—Ä 'gpt-4o-mini'")
    llm_model_fallback: str | None = Field(None, description="–ò–º—è –∑–∞–ø–∞—Å–Ω–æ–π –º–æ–¥–µ–ª–∏")
    llm_temperature: float | None = Field(None, ge=0.0, le=1.0, description="–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∫–∏ (0..1)")

class NormalizeRequest(BaseModel):
    text: str


# --- –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å ---
API_KEY_NAME = "X-API-Key"
api_key_header = APIKeyHeader(name=API_KEY_NAME, auto_error=False)

def get_api_key(api_key: str = Security(api_key_header)):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç API –∫–ª—é—á –∏–∑ –∑–∞–≥–æ–ª–æ–≤–∫–∞."""
    expected_api_key = os.getenv("API_SECRET_KEY")
    if not expected_api_key:
        logger.warning("API_SECRET_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ, –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –æ—Ç–∫–ª—é—á–µ–Ω–∞. –≠—Ç–æ –Ω–µ–±–µ–∑–æ–ø–∞—Å–Ω–æ –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞.")
        return # –†–∞–∑—Ä–µ—à–∞–µ–º –¥–æ—Å—Ç—É–ø, –µ—Å–ª–∏ –∫–ª—é—á –Ω–µ –∑–∞–¥–∞–Ω –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ
    if not api_key or api_key != expected_api_key:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="–ù–µ–≤–µ—Ä–Ω—ã–π –∏–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–π API –∫–ª—é—á",
        )
    return api_key


try:
    agent = Agent()
    logger.info("–ê–≥–µ–Ω—Ç '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç' —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
except SystemExit as e:
    logger.critical(f"–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –º–æ–∂–µ—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å—Å—è –∏–∑-–∑–∞ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏: {e}")
    agent = None
except Exception as e:
    logger.error(f"–ù–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞ '–ú–µ—Ç—Ä–æ—Ç–µ—Å—Ç': {e}", exc_info=True)
    agent = None

# --- –ì–ª–æ–±–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∑–≤–æ–Ω–∫–∞–º–∏ ---
active_calls: Dict[str, Dict[str, Any]] = {}

# --- –†–æ—É—Ç—ã ---

@app.get("/")
async def root():
    return HTMLResponse(
        "<h3>–ë—ç–∫–µ–Ω–¥ '–ú–µ—Ç—Ä–æ—Ç—ç—Å—Ç' –∞–∫—Ç–∏–≤–µ–Ω.<br>"
        "‚Ä¢ WebSocket¬†‚Äî¬†<code>/ws</code><br>"
        "‚Ä¢ UI –ª–æ–≥–æ–≤¬†‚Äî¬†<code>/logs-ui/</code><br>"
        "‚Ä¢ –¢–µ—Å—Ç –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏¬†‚Äî¬†<code>POST /api/normalize</code></h3>"
    )

# ... (–æ—Å—Ç–∞–ª—å–Ω—ã–µ —Ä–æ—É—Ç—ã –¥–ª—è –ª–æ–≥–æ–≤ –∏ CSV –æ—Å—Ç–∞—é—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
@app.get("/logs")
async def get_logs(q: str | None = None,
                   date_from: str | None = None,
                   date_to: str | None = None,
                   status: str | None = None):
    rows = await query_logs({"from": date_from, "to": date_to, "status": status})
    if q:
        q_low = q.lower()
        filtered_rows = []
        for r in rows:
            if q_low in (r.get("callerId") or "").lower():
                filtered_rows.append(r)
                continue
            try:
                transcript = json.loads(r["transcript_json"])
                for turn in transcript:
                    if q_low in turn.get("text", "").lower():
                        filtered_rows.append(r)
                        break
            except (json.JSONDecodeError, AttributeError):
                continue
        rows = filtered_rows
    return JSONResponse(content=rows)

@app.delete("/logs", dependencies=[Depends(get_api_key)])
async def clear_logs():
    try:
        await delete_all_logs()
        logger.info("üóëÔ∏è –í—Å–µ –ª–æ–≥–∏ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã.")
        return JSONResponse(content={"message": "–í—Å–µ –ª–æ–≥–∏ —É–¥–∞–ª–µ–Ω—ã"}, status_code=status.HTTP_200_OK)
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —É–¥–∞–ª–µ–Ω–∏–∏ –ª–æ–≥–æ–≤: {e}", exc_info=True)
        return JSONResponse(content={"error": str(e)}, status_code=status.HTTP_500_INTERNAL_SERVER_ERROR)

@app.get("/logs/csv")
async def get_logs_csv():
    rows = await query_logs({})
    csv_data_str = await to_csv(rows)
    response_bytes = csv_data_str.encode('utf-8-sig')
    return StreamingResponse(
        io.BytesIO(response_bytes),
        media_type="text/csv",
        headers={"Content-Disposition": 'attachment; filename="call_logs.csv"'}
    )

# --- API –¥–ª—è –ë–∞–∑—ã –ó–Ω–∞–Ω–∏–π –∏ –ü—Ä–æ–º–ø—Ç–æ–≤ ---

@app.get("/api/prompts")
async def get_prompts():
    prompts_file = os.getenv("PROMPTS_FILE_PATH")
    if not prompts_file:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PROMPTS_FILE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        with open(prompts_file, 'r', encoding='utf-8') as f:
            return json.load(f)
    except (FileNotFoundError, json.JSONDecodeError) as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∞–π–ª –ø—Ä–æ–º–ø—Ç–æ–≤: {e}")

@app.post("/api/prompts", dependencies=[Depends(get_api_key)])
async def update_prompts(payload: PromptsUpdatePayload): # NEW: –ò—Å–ø–æ–ª—å–∑—É–µ–º Pydantic –º–æ–¥–µ–ª—å
    prompts_file = os.getenv("PROMPTS_FILE_PATH")
    if not prompts_file:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è PROMPTS_FILE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        # Pydantic –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–æ–¥–µ–ª—å –≤ —Å–ª–æ–≤–∞—Ä—å
        with open(prompts_file, 'w', encoding='utf-8') as f:
            json.dump(payload.dict(), f, ensure_ascii=False, indent=2)

        # –ü–µ—Ä–µ–∑–∞–≥—Ä—É–∂–∞–µ–º –∞–≥–µ–Ω—Ç–∞, —á—Ç–æ–±—ã –æ–Ω –ø–æ–¥—Ö–≤–∞—Ç–∏–ª –Ω–æ–≤—ã–µ –ø—Ä–æ–º–ø—Ç—ã
        if agent and hasattr(agent, 'reload'):
            agent.reload()

        return JSONResponse(content={"message": "–ü—Ä–æ–º–ø—Ç—ã —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–æ–≤–ª–µ–Ω—ã."})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –ø—Ä–æ–º–ø—Ç—ã: {e}")

@app.get("/api/settings")
async def get_search_settings():
    return {
        "kb_top_k": int(os.getenv("KB_TOP_K", "3")),
        "kb_fallback_threshold": float(os.getenv("KB_FALLBACK_THRESHOLD", "0.2")),
        "llm_model_primary": os.getenv("LLM_MODEL_PRIMARY", "gpt-4o-mini"),
        "llm_model_fallback": os.getenv("LLM_MODEL_FALLBACK", ""),
        "llm_temperature": float(os.getenv("LLM_TEMPERATURE", "0.2")),
    }

@app.post("/api/settings", dependencies=[Depends(get_api_key)])
async def update_search_settings(payload: SearchSettingsPayload):
    try:
        to_set: Dict[str, str] = {}
        if payload.kb_top_k is not None:
            to_set["KB_TOP_K"] = str(payload.kb_top_k)
            os.environ["KB_TOP_K"] = str(payload.kb_top_k)
        if payload.kb_fallback_threshold is not None:
            to_set["KB_FALLBACK_THRESHOLD"] = str(payload.kb_fallback_threshold)
            os.environ["KB_FALLBACK_THRESHOLD"] = str(payload.kb_fallback_threshold)

        if to_set:
            _update_env_file(to_set)
            if agent and hasattr(agent, 'reload'):
                agent.reload()
        return JSONResponse(content={"message": "–ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {e}")


@app.post("/api/model-settings", dependencies=[Depends(get_api_key)])
async def update_model_settings(payload: ModelSettingsPayload):
    try:
        to_set: Dict[str, str] = {}
        if payload.llm_model_primary is not None:
            to_set["LLM_MODEL_PRIMARY"] = payload.llm_model_primary
            os.environ["LLM_MODEL_PRIMARY"] = payload.llm_model_primary
        if payload.llm_model_fallback is not None:
            to_set["LLM_MODEL_FALLBACK"] = payload.llm_model_fallback
            os.environ["LLM_MODEL_FALLBACK"] = payload.llm_model_fallback
        if payload.llm_temperature is not None:
            to_set["LLM_TEMPERATURE"] = str(payload.llm_temperature)
            os.environ["LLM_TEMPERATURE"] = str(payload.llm_temperature)

        if to_set:
            _update_env_file(to_set)
            if agent and hasattr(agent, 'reload'):
                agent.reload()
        return JSONResponse(content={"message": "–ú–æ–¥–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã"})
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"–ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –º–æ–¥–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏: {e}")


@app.post("/api/normalize")
async def api_normalize(payload: NormalizeRequest):
    try:
        normalized = normalize_text(payload.text)
        return {"raw": payload.text, "normalized": normalized}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/kb")
async def get_knowledge_base():
    kb_path = os.getenv("KNOWLEDGE_BASE_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        with open(kb_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return JSONResponse(content={"text": content})
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="–§–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/kb/upload", dependencies=[Depends(get_api_key)])
async def upload_kb(file: UploadFile = File(...)):
    kb_path = os.getenv("KNOWLEDGE_BASE_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

    if not file.filename.endswith('.md'):
        raise HTTPException(status_code=400, detail="–û—à–∏–±–∫–∞: –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ .md —Ñ–∞–π–ª.")

    try:
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        content_bytes = await file.read()
        content_text = content_bytes.decode('utf-8')

        # –û–±–æ–≥–∞—â–∞–µ–º —Ç–µ–∫—Å—Ç, –¥—É–±–ª–∏—Ä—É—è –∑–∞–≥–æ–ª–æ–≤–∫–∏
        logger.info("–î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ...")
        enriched_content = duplicate_headers_without_hashes(content_text)
        logger.info("–ó–∞–≥–æ–ª–æ–≤–∫–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã.")


        backup_dir = "kb/backups"
        os.makedirs(backup_dir, exist_ok=True)
        timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
        backup_path = os.path.join(backup_dir, f"knowledge_base_{timestamp}.md.bak")
        if os.path.exists(kb_path):
            shutil.copy(kb_path, backup_path)
            logger.info(f"üíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: {backup_path}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–Ω—Ç
        with open(kb_path, "w", encoding='utf-8') as buffer:
            buffer.write(enriched_content)

        logger.info(f"‚úÖ –ù–æ–≤—ã–π —Ñ–∞–π–ª –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π '{file.filename}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.")

        asyncio.create_task(recreate_embeddings_and_reload_agent())

        return JSONResponse(status_code=202, content={"message": "–§–∞–π–ª –ø—Ä–∏–Ω—è—Ç. –ù–∞—á–∞–ª—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —Ñ–∞–π–ª–∞ –ë–ó: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")

# --- –ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π (TECH) ---

@app.get("/kb2")
async def get_knowledge_base_tech():
    kb_path = os.getenv("KNOWLEDGE_BASE2_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE2_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
    try:
        with open(kb_path, 'r', encoding='utf-8') as f:
            content = f.read()
        return JSONResponse(content={"text": content})
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="–§–∞–π–ª —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.post("/kb2/upload", dependencies=[Depends(get_api_key)])
async def upload_kb_tech(file: UploadFile = File(...)):
    kb_path = os.getenv("KNOWLEDGE_BASE2_PATH")
    if not kb_path:
        raise HTTPException(status_code=500, detail="–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è –æ–∫—Ä—É–∂–µ–Ω–∏—è KNOWLEDGE_BASE2_PATH –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")

    if not file.filename.endswith('.md'):
        raise HTTPException(status_code=400, detail="–û—à–∏–±–∫–∞: –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ .md —Ñ–∞–π–ª.")

    try:
        content_bytes = await file.read()
        content_text = content_bytes.decode('utf-8')

        logger.info("[TECH KB] –î—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –≤ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–º —Ñ–∞–π–ª–µ...")
        enriched_content = duplicate_headers_without_hashes(content_text)
        logger.info("[TECH KB] –ó–∞–≥–æ–ª–æ–≤–∫–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–¥—É–±–ª–∏—Ä–æ–≤–∞–Ω—ã.")

        backup_dir = "kb/backups"
        os.makedirs(backup_dir, exist_ok=True)
        timestamp = time.strftime("%Y-%m-%d_%H-%M-%S")
        backup_path = os.path.join(backup_dir, f"knowledge_base2_{timestamp}.md.bak")
        if os.path.exists(kb_path):
            shutil.copy(kb_path, backup_path)
            logger.info(f"üíæ –°–æ–∑–¥–∞–Ω –±—ç–∫–∞–ø –¢–ï–• –ë–ó: {backup_path}")

        with open(kb_path, "w", encoding='utf-8') as buffer:
            buffer.write(enriched_content)

        logger.info(f"‚úÖ –ù–æ–≤—ã–π —Ñ–∞–π–ª –¢–ï–• –ë–ó '{file.filename}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω —Å –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–º–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏.")

        asyncio.create_task(recreate_embeddings_and_reload_agent())

        return JSONResponse(status_code=202, content={"message": "–§–∞–π–ª –ø—Ä–∏–Ω—è—Ç. –ù–∞—á–∞–ª—Å—è –ø—Ä–æ—Ü–µ—Å—Å –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –¢–ï–• –ë–ó. –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç."})

    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –¢–ï–• –ë–ó: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"–í–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞: {e}")

async def recreate_embeddings_and_reload_agent():
    logger.info("‚è≥ –ù–∞—á–∏–Ω–∞–µ–º –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ...")
    loop = asyncio.get_event_loop()
    try:
        success = await loop.run_in_executor(None, recreate_embeddings)
        if success:
            logger.info("‚úÖ –≠–º–±–µ–¥–¥–∏–Ω–≥–∏ —É—Å–ø–µ—à–Ω–æ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω—ã.")
            if agent and hasattr(agent, 'reload'):
                agent.reload()
        else:
            logger.error("‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –ü–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏ –≤ –ª–æ–≥–µ –≤—ã—à–µ.")

    except Exception as e:
        logger.error(f"‚ùå –ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ –ø–µ—Ä–µ—Å–æ–∑–¥–∞–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤: {e}", exc_info=True)


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket, callerId: str = Query(None)):
    await websocket.accept()
    session_id = str(uuid.uuid4())
    start_time = datetime.now(timezone.utc)

    active_calls[session_id] = {
        "callerId": callerId,
        "startTime": start_time.isoformat(),
        "transcript": [],
        "status": "Initiated"
    }
    logger.info(f"–ù–æ–≤—ã–π –∑–≤–æ–Ω–æ–∫: Session ID: {session_id}, Caller ID: {callerId}")

    if not agent:
        await websocket.send_text("–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–∞.")
        await websocket.close()
        del active_calls[session_id]
        return

    try:
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–∑ —Ñ–∞–π–ª–∞
        greeting = agent.prompts.get("greeting", "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ, —á–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?")
        active_calls[session_id]["transcript"].append(
            {"speaker": "bot", "text": greeting, "timestamp": datetime.now(timezone.utc).isoformat()}
        )
        await websocket.send_text(greeting)

        while True:
            data = await websocket.receive_text()
            norm = normalize_text(data)
            logger.info(f"–ü–æ–ª—É—á–µ–Ω –≤–æ–ø—Ä–æ—Å ({session_id}) RAW='{data}' NORM='{norm}'")
            active_calls[session_id]["transcript"].append(
                {"speaker": "user", "text": norm, "raw": data, "timestamp": datetime.now(timezone.utc).isoformat()}
            )

            response_generator = agent.get_response_generator(norm, session_id=session_id)

            full_response = ""
            for chunk in response_generator:
                if chunk:
                    # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–µ–∂–Ω–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ: –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è —Ç–æ–ª—å–∫–æ –≤—Ö–æ–¥–∞; –≤—ã—Ö–æ–¥ —à–ª—ë–º –∫–∞–∫ –µ—Å—Ç—å
                    await websocket.send_text(chunk)
                    full_response += chunk

            logger.info(f"–ü–æ–ª–Ω—ã–π –æ—Ç–≤–µ—Ç ({session_id}) –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω.")
            kb_used = getattr(agent, 'last_kb', None)
            active_calls[session_id]["transcript"].append(
                {
                    "speaker": "bot",
                    "text": full_response,
                    "timestamp": datetime.now(timezone.utc).isoformat(),
                    "kb": kb_used,
                }
            )
            active_calls[session_id]["status"] = "InProgress"

    except WebSocketDisconnect:
        logger.info(f"–ö–ª–∏–µ–Ω—Ç ({session_id}) –æ—Ç–∫–ª—é—á–∏–ª—Å—è.")
        active_calls[session_id]["status"] = "Completed"
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ WS ({session_id}): {e}", exc_info=True)
        active_calls[session_id]["status"] = "Failed"
    finally:
        # ... (–ª–æ–≥–∏–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –ª–æ–≥–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π) ...
        end_time = datetime.now(timezone.utc)
        call_log = active_calls.get(session_id)
        if call_log:
            log_record: Dict[str, Any] = {
                "id": session_id,
                "callerId": call_log["callerId"],
                "startTime": call_log["startTime"],
                "endTime": end_time.isoformat(),
                "status": call_log["status"],
                "transcript": call_log["transcript"],
            }
            try:
                await insert_log(log_record)
                logger.info(f"üíæ –õ–æ–≥ —Å–æ—Ö—Ä–∞–Ω—ë–Ω –¥–ª—è Session {session_id}")
            except Exception as err:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ insert_log: {err}", exc_info=True)

            del active_calls[session_id]

# --- –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ ---
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=9000)
