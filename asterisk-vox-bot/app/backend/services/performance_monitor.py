#!/usr/bin/env python3
"""
Performance Monitor –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
–¶–µ–ª—å: –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏ –∞–ª–µ—Ä—Ç—ã –¥–ª—è DevOps
"""

import asyncio
import time
import logging
import json
from datetime import datetime, timezone
from typing import Dict, List, Optional, Any
from collections import defaultdict, deque
import statistics

logger = logging.getLogger(__name__)

class PerformanceMonitor:
    """
    –ú–æ–Ω–∏—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    
    –û—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç:
    1. –í—Ä–µ–º—è –¥–æ –ø–µ—Ä–≤–æ–≥–æ –∑–≤—É–∫–∞ (–≥–ª–∞–≤–Ω–∞—è –º–µ—Ç—Ä–∏–∫–∞)
    2. –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞–º
    3. –ü–æ–∫–∞–∑–∞—Ç–µ–ª–∏ –∫–∞—á–µ—Å—Ç–≤–∞
    4. –ê–ª–µ—Ä—Ç—ã –¥–ª—è DevOps
    """
    
    def __init__(self):
        # –ú–µ—Ç—Ä–∏–∫–∏ –ø–æ –∫–∞–Ω–∞–ª–∞–º
        self.channel_metrics: Dict[str, Dict] = defaultdict(dict)
        
        # –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        self.aggregated_metrics = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "avg_response_time": 0.0,
            "avg_first_chunk_time": 0.0,
            "avg_filler_time": 0.0,
            "avg_grpc_tts_time": 0.0,
            "barge_in_rate": 0.0,
            "fallback_rate": 0.0
        }
        
        # –°–∫–æ–ª—å–∑—è—â–∏–µ –æ–∫–Ω–∞ –¥–ª—è –º–µ—Ç—Ä–∏–∫
        self.response_times = deque(maxlen=100)  # –ü–æ—Å–ª–µ–¥–Ω–∏–µ 100 –∑–∞–ø—Ä–æ—Å–æ–≤
        self.first_chunk_times = deque(maxlen=100)
        self.filler_times = deque(maxlen=100)
        self.grpc_tts_times = deque(maxlen=100)
        
        # –ü–æ—Ä–æ–≥–∏ –¥–ª—è –∞–ª–µ—Ä—Ç–æ–≤
        self.alert_thresholds = {
            "response_time_critical": 3.0,  # –ö—Ä–∏—Ç–∏—á–Ω–æ: >3 —Å–µ–∫—É–Ω–¥
            "response_time_warning": 2.0,   # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: >2 —Å–µ–∫—É–Ω–¥
            "first_chunk_critical": 1.5,    # –ö—Ä–∏—Ç–∏—á–Ω–æ: >1.5 —Å–µ–∫—É–Ω–¥
            "first_chunk_warning": 1.0,     # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: >1 —Å–µ–∫—É–Ω–¥
            "grpc_tts_critical": 0.5,       # –ö—Ä–∏—Ç–∏—á–Ω–æ: >0.5 —Å–µ–∫—É–Ω–¥
            "grpc_tts_warning": 0.3,        # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: >0.3 —Å–µ–∫—É–Ω–¥
            "fallback_rate_critical": 0.1,  # –ö—Ä–∏—Ç–∏—á–Ω–æ: >10% fallback
            "fallback_rate_warning": 0.05   # –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: >5% fallback
        }
        
        # –ê–ª–µ—Ä—Ç—ã
        self.active_alerts: List[Dict] = []
        self.alert_history: List[Dict] = []
        
        logger.info("üìä PerformanceMonitor –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
    
    def start_request(self, channel_id: str, user_text: str) -> str:
        """
        –ù–∞—á–∏–Ω–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            channel_id: ID –∫–∞–Ω–∞–ª–∞
            user_text: –¢–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            
        Returns:
            str: ID –∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
        """
        request_id = f"{channel_id}_{int(time.time() * 1000)}"
        
        self.channel_metrics[channel_id] = {
            "request_id": request_id,
            "user_text": user_text,
            "start_time": time.time(),
            "asr_complete_time": None,
            "first_chunk_time": None,
            "first_audio_time": None,
            "filler_time": None,
            "grpc_tts_time": None,
            "total_time": None,
            "barge_in_count": 0,
            "fallback_used": False,
            "status": "processing"
        }
        
        logger.info(f"üìä Started monitoring request {request_id} for {channel_id}")
        return request_id
    
    def log_asr_complete(self, channel_id: str, asr_time: float):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ ASR"""
        if channel_id in self.channel_metrics:
            self.channel_metrics[channel_id]["asr_complete_time"] = asr_time
            logger.debug(f"üìä ASR complete for {channel_id}: {asr_time:.2f}s")
    
    def log_first_chunk(self, channel_id: str, chunk_time: float):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞"""
        if channel_id in self.channel_metrics:
            self.channel_metrics[channel_id]["first_chunk_time"] = chunk_time
            self.first_chunk_times.append(chunk_time)
            logger.debug(f"üìä First chunk for {channel_id}: {chunk_time:.2f}s")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
            self._check_first_chunk_alerts(channel_id, chunk_time)
    
    def log_first_audio(self, channel_id: str, audio_time: float):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è –ø–µ—Ä–≤–æ–≥–æ –∞—É–¥–∏–æ"""
        if channel_id in self.channel_metrics:
            self.channel_metrics[channel_id]["first_audio_time"] = audio_time
            logger.debug(f"üìä First audio for {channel_id}: {audio_time:.2f}s")
    
    def log_filler_time(self, channel_id: str, filler_time: float):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è filler"""
        if channel_id in self.channel_metrics:
            self.channel_metrics[channel_id]["filler_time"] = filler_time
            self.filler_times.append(filler_time)
            logger.debug(f"üìä Filler time for {channel_id}: {filler_time:.2f}s")
    
    def log_grpc_tts_time(self, channel_id: str, tts_time: float):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –≤—Ä–µ–º—è gRPC TTS"""
        if channel_id in self.channel_metrics:
            self.channel_metrics[channel_id]["grpc_tts_time"] = tts_time
            self.grpc_tts_times.append(tts_time)
            logger.debug(f"üìä gRPC TTS time for {channel_id}: {tts_time:.2f}s")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
            self._check_grpc_tts_alerts(channel_id, tts_time)
    
    def log_barge_in(self, channel_id: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç barge-in"""
        if channel_id in self.channel_metrics:
            self.channel_metrics[channel_id]["barge_in_count"] += 1
            logger.debug(f"üìä Barge-in for {channel_id}")
    
    def log_fallback(self, channel_id: str):
        """–õ–æ–≥–∏—Ä—É–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ fallback"""
        if channel_id in self.channel_metrics:
            self.channel_metrics[channel_id]["fallback_used"] = True
            logger.debug(f"üìä Fallback used for {channel_id}")
    
    def complete_request(self, channel_id: str, success: bool = True):
        """
        –ó–∞–≤–µ—Ä—à–∞–µ—Ç –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∞
        
        Args:
            channel_id: ID –∫–∞–Ω–∞–ª–∞
            success: –£—Å–ø–µ—à–Ω–æ—Å—Ç—å –∑–∞–ø—Ä–æ—Å–∞
        """
        if channel_id not in self.channel_metrics:
            return
        
        metrics = self.channel_metrics[channel_id]
        metrics["total_time"] = time.time() - metrics["start_time"]
        metrics["status"] = "completed" if success else "failed"
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏
        self.response_times.append(metrics["total_time"])
        self.aggregated_metrics["total_requests"] += 1
        
        if success:
            self.aggregated_metrics["successful_requests"] += 1
        else:
            self.aggregated_metrics["failed_requests"] += 1
        
        # –û–±–Ω–æ–≤–ª—è–µ–º —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è
        self._update_aggregated_metrics()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–ª–µ—Ä—Ç—ã
        self._check_response_time_alerts(channel_id, metrics["total_time"])
        
        logger.info(f"üìä Completed monitoring for {channel_id}: {metrics['total_time']:.2f}s")
    
    def _update_aggregated_metrics(self):
        """–û–±–Ω–æ–≤–ª—è–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
        try:
            if self.response_times:
                self.aggregated_metrics["avg_response_time"] = statistics.mean(self.response_times)
            
            if self.first_chunk_times:
                self.aggregated_metrics["avg_first_chunk_time"] = statistics.mean(self.first_chunk_times)
            
            if self.filler_times:
                self.aggregated_metrics["avg_filler_time"] = statistics.mean(self.filler_times)
            
            if self.grpc_tts_times:
                self.aggregated_metrics["avg_grpc_tts_time"] = statistics.mean(self.grpc_tts_times)
            
            # Barge-in rate
            total_requests = self.aggregated_metrics["total_requests"]
            if total_requests > 0:
                barge_in_count = sum(1 for metrics in self.channel_metrics.values() 
                                   if metrics.get("barge_in_count", 0) > 0)
                self.aggregated_metrics["barge_in_rate"] = barge_in_count / total_requests
                
                # Fallback rate
                fallback_count = sum(1 for metrics in self.channel_metrics.values() 
                                   if metrics.get("fallback_used", False))
                self.aggregated_metrics["fallback_rate"] = fallback_count / total_requests
                
        except Exception as e:
            logger.error(f"‚ùå Update aggregated metrics error: {e}")
    
    def _check_response_time_alerts(self, channel_id: str, response_time: float):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–ª–µ—Ä—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞"""
        try:
            if response_time > self.alert_thresholds["response_time_critical"]:
                self._create_alert("CRITICAL", "response_time", 
                                 f"Response time {response_time:.2f}s > {self.alert_thresholds['response_time_critical']}s",
                                 channel_id, response_time)
            elif response_time > self.alert_thresholds["response_time_warning"]:
                self._create_alert("WARNING", "response_time",
                                 f"Response time {response_time:.2f}s > {self.alert_thresholds['response_time_warning']}s",
                                 channel_id, response_time)
        except Exception as e:
            logger.error(f"‚ùå Response time alert check error: {e}")
    
    def _check_first_chunk_alerts(self, channel_id: str, chunk_time: float):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–ª–µ—Ä—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–µ—Ä–≤–æ–≥–æ —á–∞–Ω–∫–∞"""
        try:
            if chunk_time > self.alert_thresholds["first_chunk_critical"]:
                self._create_alert("CRITICAL", "first_chunk",
                                 f"First chunk time {chunk_time:.2f}s > {self.alert_thresholds['first_chunk_critical']}s",
                                 channel_id, chunk_time)
            elif chunk_time > self.alert_thresholds["first_chunk_warning"]:
                self._create_alert("WARNING", "first_chunk",
                                 f"First chunk time {chunk_time:.2f}s > {self.alert_thresholds['first_chunk_warning']}s",
                                 channel_id, chunk_time)
        except Exception as e:
            logger.error(f"‚ùå First chunk alert check error: {e}")
    
    def _check_grpc_tts_alerts(self, channel_id: str, tts_time: float):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∞–ª–µ—Ä—Ç—ã –ø–æ –≤—Ä–µ–º–µ–Ω–∏ gRPC TTS"""
        try:
            if tts_time > self.alert_thresholds["grpc_tts_critical"]:
                self._create_alert("CRITICAL", "grpc_tts",
                                 f"gRPC TTS time {tts_time:.2f}s > {self.alert_thresholds['grpc_tts_critical']}s",
                                 channel_id, tts_time)
            elif tts_time > self.alert_thresholds["grpc_tts_warning"]:
                self._create_alert("WARNING", "grpc_tts",
                                 f"gRPC TTS time {tts_time:.2f}s > {self.alert_thresholds['grpc_tts_warning']}s",
                                 channel_id, tts_time)
        except Exception as e:
            logger.error(f"‚ùå gRPC TTS alert check error: {e}")
    
    def _create_alert(self, level: str, alert_type: str, message: str, channel_id: str, value: float):
        """–°–æ–∑–¥–∞–µ—Ç –∞–ª–µ—Ä—Ç"""
        try:
            alert = {
                "id": f"{alert_type}_{int(time.time() * 1000)}",
                "level": level,
                "type": alert_type,
                "message": message,
                "channel_id": channel_id,
                "value": value,
                "timestamp": datetime.now(timezone.utc).isoformat(),
                "resolved": False
            }
            
            self.active_alerts.append(alert)
            self.alert_history.append(alert)
            
            # –õ–æ–≥–∏—Ä—É–µ–º –∞–ª–µ—Ä—Ç
            if level == "CRITICAL":
                logger.error(f"üö® CRITICAL ALERT: {message}")
            else:
                logger.warning(f"‚ö†Ô∏è WARNING ALERT: {message}")
            
            # –í —Ä–µ–∞–ª—å–Ω–æ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ –∑–¥–µ—Å—å –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–∫–∞ –≤ —Å–∏—Å—Ç–µ–º—É –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
            # await self._send_alert_to_monitoring_system(alert)
            
        except Exception as e:
            logger.error(f"‚ùå Create alert error: {e}")
    
    def get_channel_metrics(self, channel_id: str) -> Optional[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –∫–∞–Ω–∞–ª–∞"""
        return self.channel_metrics.get(channel_id)
    
    def get_aggregated_metrics(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏"""
        return self.aggregated_metrics.copy()
    
    def get_active_alerts(self) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã–µ –∞–ª–µ—Ä—Ç—ã"""
        return self.active_alerts.copy()
    
    def get_alert_history(self, limit: int = 100) -> List[Dict]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å—Ç–æ—Ä–∏—é –∞–ª–µ—Ä—Ç–æ–≤"""
        return self.alert_history[-limit:]
    
    def resolve_alert(self, alert_id: str):
        """–†–∞–∑—Ä–µ—à–∞–µ—Ç –∞–ª–µ—Ä—Ç"""
        try:
            for alert in self.active_alerts:
                if alert["id"] == alert_id:
                    alert["resolved"] = True
                    alert["resolved_at"] = datetime.now(timezone.utc).isoformat()
                    self.active_alerts.remove(alert)
                    logger.info(f"‚úÖ Resolved alert: {alert_id}")
                    break
        except Exception as e:
            logger.error(f"‚ùå Resolve alert error: {e}")
    
    def clear_channel_metrics(self, channel_id: str):
        """–û—á–∏—â–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –∫–∞–Ω–∞–ª–∞"""
        if channel_id in self.channel_metrics:
            del self.channel_metrics[channel_id]
            logger.debug(f"üßπ Cleared metrics for {channel_id}")
    
    def get_dashboard_data(self) -> Dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è dashboard"""
        try:
            return {
                "aggregated_metrics": self.get_aggregated_metrics(),
                "active_alerts": self.get_active_alerts(),
                "recent_alerts": self.get_alert_history(10),
                "performance_summary": {
                    "avg_response_time": self.aggregated_metrics["avg_response_time"],
                    "avg_first_chunk_time": self.aggregated_metrics["avg_first_chunk_time"],
                    "avg_filler_time": self.aggregated_metrics["avg_filler_time"],
                    "avg_grpc_tts_time": self.aggregated_metrics["avg_grpc_tts_time"],
                    "success_rate": (self.aggregated_metrics["successful_requests"] / 
                                   max(self.aggregated_metrics["total_requests"], 1)) * 100,
                    "barge_in_rate": self.aggregated_metrics["barge_in_rate"] * 100,
                    "fallback_rate": self.aggregated_metrics["fallback_rate"] * 100
                }
            }
        except Exception as e:
            logger.error(f"‚ùå Get dashboard data error: {e}")
            return {}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª—è—Ö
performance_monitor = PerformanceMonitor()

def get_performance_monitor() -> PerformanceMonitor:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä PerformanceMonitor"""
    return performance_monitor

